{"version":3,"file":"lib.modern.js","sources":["../src/BaseConversation.ts","../src/utils/BaseConnection.ts","../src/version.ts","../src/utils/events.ts","../src/utils/overrides.ts","../src/utils/WebSocketConnection.ts","../src/utils/audio.ts","../src/utils/createWorkletModuleLoader.ts","../src/utils/rawAudioProcessor.generated.ts","../src/utils/WebRTCConnection.ts","../src/utils/ConnectionFactory.ts","../src/utils/compatibility.ts","../src/utils/applyDelay.ts","../src/TextConversation.ts","../src/utils/input.ts","../src/utils/audioConcatProcessor.generated.ts","../src/utils/output.ts","../src/VoiceConversation.ts","../src/utils/postOverallFeedback.ts","../src/scribe/connection.ts","../src/utils/scribeAudioProcessor.generated.ts","../src/scribe/scribe.ts","../src/index.ts"],"sourcesContent":["import { Callbacks, Mode, Status } from \"@elevenlabs/types\";\nimport type {\n  BaseConnection,\n  DisconnectionDetails,\n  SessionConfig,\n  FormatConfig,\n} from \"./utils/BaseConnection\";\nimport type {\n  AgentAudioEvent,\n  AgentChatResponsePartEvent,\n  AgentResponseEvent,\n  ClientToolCallEvent,\n  IncomingSocketEvent,\n  InternalTentativeAgentResponseEvent,\n  InterruptionEvent,\n  UserTranscriptionEvent,\n  VadScoreEvent,\n  MCPToolCallClientEvent,\n  AgentToolResponseEvent,\n  ConversationMetadataEvent,\n  AsrInitiationMetadataEvent,\n  MCPConnectionStatusEvent,\n  ErrorMessageEvent,\n  AgentToolRequestEvent,\n} from \"./utils/events\";\nimport type { InputConfig } from \"./utils/input\";\nimport type { OutputConfig } from \"./utils/output\";\n\nexport type { Role, Mode, Status, Callbacks } from \"@elevenlabs/types\";\n\n/** Allows self-hosting the worklets to avoid whitelisting blob: and data: in the CSP script-src  */\nexport type AudioWorkletConfig = {\n  workletPaths?: {\n    rawAudioProcessor?: string;\n    audioConcatProcessor?: string;\n  };\n  libsampleratePath?: string;\n};\n\nexport type Options = SessionConfig &\n  Callbacks &\n  ClientToolsConfig &\n  InputConfig &\n  OutputConfig &\n  AudioWorkletConfig;\n\nexport type PartialOptions = SessionConfig &\n  Partial<Callbacks> &\n  Partial<ClientToolsConfig> &\n  Partial<InputConfig> &\n  Partial<OutputConfig> &\n  Partial<FormatConfig> &\n  Partial<AudioWorkletConfig>;\n\nexport type ClientToolsConfig = {\n  clientTools: Record<\n    string,\n    (\n      parameters: any\n    ) => Promise<string | number | void> | string | number | void\n  >;\n};\n\nconst EMPTY_FREQUENCY_DATA = new Uint8Array(0);\n\nexport class BaseConversation {\n  protected lastInterruptTimestamp = 0;\n  protected mode: Mode = \"listening\";\n  protected status: Status = \"connecting\";\n  protected volume = 1;\n  protected currentEventId = 1;\n  protected lastFeedbackEventId = 0;\n  protected canSendFeedback = false;\n\n  protected static getFullOptions(partialOptions: PartialOptions): Options {\n    return {\n      clientTools: {},\n      onConnect: () => {},\n      onDebug: () => {},\n      onDisconnect: () => {},\n      onError: () => {},\n      onMessage: () => {},\n      onAudio: () => {},\n      onModeChange: () => {},\n      onStatusChange: () => {},\n      onCanSendFeedbackChange: () => {},\n      onInterruption: () => {},\n      ...partialOptions,\n    };\n  }\n\n  protected constructor(\n    protected readonly options: Options,\n    protected readonly connection: BaseConnection\n  ) {\n    if (this.options.onConnect) {\n      this.options.onConnect({ conversationId: connection.conversationId });\n    }\n    this.connection.onMessage(this.onMessage);\n    this.connection.onDisconnect(this.endSessionWithDetails);\n    this.connection.onModeChange(mode => this.updateMode(mode));\n    this.updateStatus(\"connected\");\n  }\n\n  public endSession() {\n    return this.endSessionWithDetails({ reason: \"user\" });\n  }\n\n  private endSessionWithDetails = async (details: DisconnectionDetails) => {\n    if (this.status !== \"connected\" && this.status !== \"connecting\") return;\n    this.updateStatus(\"disconnecting\");\n    await this.handleEndSession();\n    this.updateStatus(\"disconnected\");\n    if (this.options.onDisconnect) {\n      this.options.onDisconnect(details);\n    }\n  };\n\n  protected async handleEndSession() {\n    this.connection.close();\n  }\n\n  protected updateMode(mode: Mode) {\n    if (mode !== this.mode) {\n      this.mode = mode;\n      if (this.options.onModeChange) {\n        this.options.onModeChange({ mode });\n      }\n    }\n  }\n\n  protected updateStatus(status: Status) {\n    if (status !== this.status) {\n      this.status = status;\n      if (this.options.onStatusChange) {\n        this.options.onStatusChange({ status });\n      }\n    }\n  }\n\n  protected updateCanSendFeedback() {\n    const canSendFeedback = this.currentEventId !== this.lastFeedbackEventId;\n    if (this.canSendFeedback !== canSendFeedback) {\n      this.canSendFeedback = canSendFeedback;\n      if (this.options.onCanSendFeedbackChange) {\n        this.options.onCanSendFeedbackChange({ canSendFeedback });\n      }\n    }\n  }\n\n  protected handleInterruption(event: InterruptionEvent) {\n    if (event.interruption_event) {\n      this.lastInterruptTimestamp = event.interruption_event.event_id;\n\n      if (this.options.onInterruption) {\n        this.options.onInterruption({\n          event_id: event.interruption_event.event_id,\n        });\n      }\n    }\n  }\n\n  protected handleAgentResponse(event: AgentResponseEvent) {\n    if (this.options.onMessage) {\n      this.options.onMessage({\n        source: \"ai\",\n        role: \"agent\",\n        message: event.agent_response_event.agent_response,\n      });\n    }\n  }\n\n  protected handleUserTranscript(event: UserTranscriptionEvent) {\n    if (this.options.onMessage) {\n      this.options.onMessage({\n        source: \"user\",\n        role: \"user\",\n        message: event.user_transcription_event.user_transcript,\n      });\n    }\n  }\n\n  protected handleTentativeAgentResponse(\n    event: InternalTentativeAgentResponseEvent\n  ) {\n    if (this.options.onDebug) {\n      this.options.onDebug({\n        type: \"tentative_agent_response\",\n        response:\n          event.tentative_agent_response_internal_event\n            .tentative_agent_response,\n      });\n    }\n  }\n\n  protected handleVadScore(event: VadScoreEvent) {\n    if (this.options.onVadScore) {\n      this.options.onVadScore({\n        vadScore: event.vad_score_event.vad_score,\n      });\n    }\n  }\n\n  protected async handleClientToolCall(event: ClientToolCallEvent) {\n    if (\n      Object.prototype.hasOwnProperty.call(\n        this.options.clientTools,\n        event.client_tool_call.tool_name\n      )\n    ) {\n      try {\n        const result =\n          (await this.options.clientTools[event.client_tool_call.tool_name](\n            event.client_tool_call.parameters\n          )) ?? \"Client tool execution successful.\"; // default client-tool call response\n\n        // The API expects result to be a string, so we need to convert it if it's not already a string\n        const formattedResult =\n          typeof result === \"object\" ? JSON.stringify(result) : String(result);\n\n        this.connection.sendMessage({\n          type: \"client_tool_result\",\n          tool_call_id: event.client_tool_call.tool_call_id,\n          result: formattedResult,\n          is_error: false,\n        });\n      } catch (e) {\n        this.onError(\n          `Client tool execution failed with following error: ${(e as Error)?.message}`,\n          {\n            clientToolName: event.client_tool_call.tool_name,\n          }\n        );\n        this.connection.sendMessage({\n          type: \"client_tool_result\",\n          tool_call_id: event.client_tool_call.tool_call_id,\n          result: `Client tool execution failed: ${(e as Error)?.message}`,\n          is_error: true,\n        });\n      }\n    } else {\n      if (this.options.onUnhandledClientToolCall) {\n        this.options.onUnhandledClientToolCall(event.client_tool_call);\n\n        return;\n      }\n\n      this.onError(\n        `Client tool with name ${event.client_tool_call.tool_name} is not defined on client`,\n        {\n          clientToolName: event.client_tool_call.tool_name,\n        }\n      );\n      this.connection.sendMessage({\n        type: \"client_tool_result\",\n        tool_call_id: event.client_tool_call.tool_call_id,\n        result: `Client tool with name ${event.client_tool_call.tool_name} is not defined on client`,\n        is_error: true,\n      });\n    }\n  }\n\n  protected handleAudio(event: AgentAudioEvent) {}\n\n  protected handleMCPToolCall(event: MCPToolCallClientEvent) {\n    if (this.options.onMCPToolCall) {\n      this.options.onMCPToolCall(event.mcp_tool_call);\n    }\n  }\n\n  protected handleMCPConnectionStatus(event: MCPConnectionStatusEvent) {\n    if (this.options.onMCPConnectionStatus) {\n      this.options.onMCPConnectionStatus(event.mcp_connection_status);\n    }\n  }\n\n  protected handleAgentToolRequest(event: AgentToolRequestEvent) {\n    if (this.options.onAgentToolRequest) {\n      this.options.onAgentToolRequest(event.agent_tool_request);\n    }\n  }\n\n  protected handleAgentToolResponse(event: AgentToolResponseEvent) {\n    if (event.agent_tool_response.tool_name === \"end_call\") {\n      this.endSessionWithDetails({\n        reason: \"agent\",\n        context: new CloseEvent(\"end_call\", { reason: \"Agent ended the call\" }),\n      });\n    }\n\n    if (this.options.onAgentToolResponse) {\n      this.options.onAgentToolResponse(event.agent_tool_response);\n    }\n  }\n\n  protected handleConversationMetadata(event: ConversationMetadataEvent) {\n    if (this.options.onConversationMetadata) {\n      this.options.onConversationMetadata(\n        event.conversation_initiation_metadata_event\n      );\n    }\n  }\n\n  protected handleAsrInitiationMetadata(event: AsrInitiationMetadataEvent) {\n    if (this.options.onAsrInitiationMetadata) {\n      this.options.onAsrInitiationMetadata(event.asr_initiation_metadata_event);\n    }\n  }\n\n  protected handleAgentChatResponsePart(event: AgentChatResponsePartEvent) {\n    if (this.options.onAgentChatResponsePart) {\n      this.options.onAgentChatResponsePart(event.text_response_part);\n    }\n  }\n\n  protected handleErrorEvent(event: ErrorMessageEvent) {\n    const errorType = event.error_event.error_type;\n    const message =\n      event.error_event.message || event.error_event.reason || \"Unknown error\";\n\n    if (errorType === \"max_duration_exceeded\") {\n      this.endSessionWithDetails({\n        reason: \"error\",\n        message: message,\n        context: new Event(\"max_duration_exceeded\"),\n      });\n      return;\n    }\n\n    this.onError(`Server error: ${message}`, {\n      errorType,\n      code: event.error_event.code,\n      debugMessage: event.error_event.debug_message,\n      details: event.error_event.details,\n    });\n  }\n\n  private onMessage = async (parsedEvent: IncomingSocketEvent) => {\n    switch (parsedEvent.type) {\n      case \"interruption\": {\n        this.handleInterruption(parsedEvent);\n        return;\n      }\n      case \"agent_response\": {\n        this.handleAgentResponse(parsedEvent);\n        return;\n      }\n      case \"user_transcript\": {\n        this.handleUserTranscript(parsedEvent);\n        return;\n      }\n      case \"internal_tentative_agent_response\": {\n        this.handleTentativeAgentResponse(parsedEvent);\n        return;\n      }\n      case \"client_tool_call\": {\n        try {\n          await this.handleClientToolCall(parsedEvent);\n        } catch (error) {\n          this.onError(\n            `Unexpected error in client tool call handling: ${error instanceof Error ? error.message : String(error)}`,\n            {\n              clientToolName: parsedEvent.client_tool_call.tool_name,\n              toolCallId: parsedEvent.client_tool_call.tool_call_id,\n            }\n          );\n        }\n        return;\n      }\n      case \"audio\": {\n        this.handleAudio(parsedEvent);\n        return;\n      }\n\n      case \"vad_score\": {\n        this.handleVadScore(parsedEvent);\n        return;\n      }\n\n      case \"ping\": {\n        this.connection.sendMessage({\n          type: \"pong\",\n          event_id: parsedEvent.ping_event.event_id,\n        });\n        // parsedEvent.ping_event.ping_ms can be used on client side, for example\n        // to warn if ping is too high that experience might be degraded.\n        return;\n      }\n\n      case \"mcp_tool_call\": {\n        this.handleMCPToolCall(parsedEvent);\n        return;\n      }\n\n      case \"mcp_connection_status\": {\n        this.handleMCPConnectionStatus(parsedEvent);\n        return;\n      }\n\n      case \"agent_tool_request\": {\n        this.handleAgentToolRequest(parsedEvent);\n        return;\n      }\n\n      case \"agent_tool_response\": {\n        this.handleAgentToolResponse(parsedEvent);\n        return;\n      }\n\n      case \"conversation_initiation_metadata\": {\n        this.handleConversationMetadata(parsedEvent);\n        return;\n      }\n\n      case \"asr_initiation_metadata\": {\n        this.handleAsrInitiationMetadata(parsedEvent);\n        return;\n      }\n\n      case \"agent_chat_response_part\": {\n        this.handleAgentChatResponsePart(parsedEvent);\n        return;\n      }\n\n      case \"error\": {\n        this.handleErrorEvent(parsedEvent);\n        return;\n      }\n\n      default: {\n        if (this.options.onDebug) {\n          this.options.onDebug(parsedEvent);\n        }\n        return;\n      }\n    }\n  };\n\n  private onError(message: string, context?: any) {\n    console.error(message, context);\n    if (this.options.onError) {\n      this.options.onError(message, context);\n    }\n  }\n\n  public getId() {\n    return this.connection.conversationId;\n  }\n\n  public isOpen() {\n    return this.status === \"connected\";\n  }\n\n  public setVolume = ({ volume }: { volume: number }) => {\n    this.volume = volume;\n  };\n\n  public setMicMuted(isMuted: boolean) {\n    this.connection.setMicMuted(isMuted);\n  }\n\n  public getInputByteFrequencyData(): Uint8Array {\n    return EMPTY_FREQUENCY_DATA;\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array {\n    return EMPTY_FREQUENCY_DATA;\n  }\n\n  public getInputVolume() {\n    return 0;\n  }\n\n  public getOutputVolume() {\n    return 0;\n  }\n\n  public sendFeedback(like: boolean) {\n    if (!this.canSendFeedback) {\n      console.warn(\n        this.lastFeedbackEventId === 0\n          ? \"Cannot send feedback: the conversation has not started yet.\"\n          : \"Cannot send feedback: feedback has already been sent for the current response.\"\n      );\n      return;\n    }\n\n    this.connection.sendMessage({\n      type: \"feedback\",\n      score: like ? \"like\" : \"dislike\",\n      event_id: this.currentEventId,\n    });\n    this.lastFeedbackEventId = this.currentEventId;\n    this.updateCanSendFeedback();\n  }\n\n  public sendContextualUpdate(text: string) {\n    this.connection.sendMessage({\n      type: \"contextual_update\",\n      text,\n    });\n  }\n\n  public sendUserMessage(text: string) {\n    this.connection.sendMessage({\n      type: \"user_message\",\n      text,\n    });\n  }\n\n  public sendUserActivity() {\n    this.connection.sendMessage({\n      type: \"user_activity\",\n    });\n  }\n\n  public sendMCPToolApprovalResult(toolCallId: string, isApproved: boolean) {\n    this.connection.sendMessage({\n      type: \"mcp_tool_approval_result\",\n      tool_call_id: toolCallId,\n      is_approved: isApproved,\n    });\n  }\n}\n","import type { IncomingSocketEvent, OutgoingSocketEvent } from \"./events\";\nimport type { Mode } from \"../BaseConversation\";\nimport type { ConversationConfigOverrideAgentLanguage as Language } from \"@elevenlabs/types/generated/types/asyncapi-types\";\nimport type { DisconnectionDetails } from \"@elevenlabs/types\";\n\nexport type {\n  DisconnectionDetails,\n  ConversationConfigOverrideAgentLanguage as Language,\n} from \"@elevenlabs/types\";\n\nexport type DelayConfig = {\n  default: number;\n  android?: number;\n  ios?: number;\n};\n\nexport type FormatConfig = {\n  format: \"pcm\" | \"ulaw\";\n  sampleRate: number;\n  outputDeviceId?: string;\n};\n\nexport type OnDisconnectCallback = (details: DisconnectionDetails) => void;\nexport type OnMessageCallback = (event: IncomingSocketEvent) => void;\n\nexport type BaseSessionConfig = {\n  origin?: string;\n  authorization?: string;\n  livekitUrl?: string;\n  overrides?: {\n    agent?: {\n      prompt?: {\n        prompt?: string;\n      };\n      firstMessage?: string;\n      language?: Language;\n    };\n    tts?: {\n      voiceId?: string;\n    };\n    conversation?: {\n      textOnly?: boolean;\n    };\n    client?: {\n      source?: string;\n      version?: string;\n    };\n  };\n  customLlmExtraBody?: unknown;\n  dynamicVariables?: Record<string, string | number | boolean>;\n  useWakeLock?: boolean;\n  connectionDelay?: DelayConfig;\n  textOnly?: boolean;\n  userId?: string;\n};\n\nexport type ConnectionType = \"websocket\" | \"webrtc\";\n\nexport type PublicSessionConfig = BaseSessionConfig & {\n  agentId: string;\n  connectionType: ConnectionType;\n  signedUrl?: never;\n  conversationToken?: never;\n};\n\nexport type PrivateWebSocketSessionConfig = BaseSessionConfig & {\n  signedUrl: string;\n  connectionType?: \"websocket\";\n  agentId?: never;\n  conversationToken?: never;\n};\n\nexport type PrivateWebRTCSessionConfig = BaseSessionConfig & {\n  conversationToken: string;\n  connectionType?: \"webrtc\";\n  agentId?: never;\n  signedUrl?: never;\n};\n\n// Union type for all possible session configurations\nexport type SessionConfig =\n  | PublicSessionConfig\n  | PrivateWebSocketSessionConfig\n  | PrivateWebRTCSessionConfig;\n\nexport abstract class BaseConnection {\n  public abstract readonly conversationId: string;\n  public abstract readonly inputFormat: FormatConfig;\n  public abstract readonly outputFormat: FormatConfig;\n\n  protected queue: IncomingSocketEvent[] = [];\n  protected disconnectionDetails: DisconnectionDetails | null = null;\n  protected onDisconnectCallback: OnDisconnectCallback | null = null;\n  protected onMessageCallback: OnMessageCallback | null = null;\n  protected onModeChangeCallback: ((mode: Mode) => void) | null = null;\n  protected onDebug?: (info: unknown) => void;\n\n  constructor(config: { onDebug?: (info: unknown) => void } = {}) {\n    this.onDebug = config.onDebug;\n  }\n\n  protected debug(info: unknown) {\n    if (this.onDebug) this.onDebug(info);\n  }\n\n  public abstract close(): void;\n  public abstract sendMessage(message: OutgoingSocketEvent): void;\n  public abstract setMicMuted(isMuted: boolean): Promise<void>;\n\n  public onMessage(callback: OnMessageCallback) {\n    this.onMessageCallback = callback;\n    const queue = this.queue;\n    this.queue = [];\n\n    if (queue.length > 0) {\n      // Make sure the queue is flushed after the constructors finishes and\n      // classes are initialized.\n      queueMicrotask(() => {\n        queue.forEach(callback);\n      });\n    }\n  }\n\n  public onDisconnect(callback: OnDisconnectCallback) {\n    this.onDisconnectCallback = callback;\n    const details = this.disconnectionDetails;\n    if (details) {\n      // Make sure the event is triggered after the constructors finishes and\n      // classes are initialized.\n      queueMicrotask(() => {\n        callback(details);\n      });\n    }\n  }\n\n  public onModeChange(callback: (mode: Mode) => void) {\n    this.onModeChangeCallback = callback;\n  }\n\n  protected updateMode(mode: Mode) {\n    this.onModeChangeCallback?.(mode);\n  }\n\n  protected disconnect(details: DisconnectionDetails) {\n    if (!this.disconnectionDetails) {\n      this.disconnectionDetails = details;\n      this.onDisconnectCallback?.(details);\n    }\n  }\n\n  protected handleMessage(parsedEvent: IncomingSocketEvent) {\n    if (this.onMessageCallback) {\n      this.onMessageCallback(parsedEvent);\n    } else {\n      this.queue.push(parsedEvent);\n    }\n  }\n}\n\nexport function parseFormat(format: string): FormatConfig {\n  const [formatPart, sampleRatePart] = format.split(\"_\");\n  if (![\"pcm\", \"ulaw\"].includes(formatPart)) {\n    throw new Error(`Invalid format: ${format}`);\n  }\n\n  const sampleRate = Number.parseInt(sampleRatePart);\n  if (Number.isNaN(sampleRate)) {\n    throw new Error(`Invalid sample rate: ${sampleRatePart}`);\n  }\n\n  return {\n    format: formatPart as FormatConfig[\"format\"],\n    sampleRate,\n  };\n}\n","// This file is auto-generated during build\nexport const PACKAGE_VERSION = \"0.12.0\";\n","import { Outgoing } from \"@elevenlabs/types\";\nimport {\n  AgentChatResponsePartClientEvent,\n  AgentResponse,\n  AgentResponseCorrection,\n  AgentToolResponseClientEvent,\n  AsrInitiationMetadataEvent as AsrMetadataEvent,\n  Audio,\n  AgentToolRequestClientEvent,\n  ClientToolCallMessage,\n  ConversationMetadata,\n  ErrorMessage,\n  Interruption,\n  McpConnectionStatusClientEvent,\n  McpToolCall,\n  Ping,\n  InternalTentativeAgentResponse as TentativeAgentResponseInternal,\n  UserTranscript,\n  VadScore,\n} from \"@elevenlabs/types/generated/types/asyncapi-types\";\n\n// Compatibility layer - incoming events\nexport type UserTranscriptionEvent = UserTranscript;\nexport type AgentResponseEvent = AgentResponse;\nexport type AgentAudioEvent = Audio;\nexport type InterruptionEvent = Interruption;\nexport type InternalTentativeAgentResponseEvent =\n  TentativeAgentResponseInternal;\nexport type ConfigEvent = ConversationMetadata;\nexport type PingEvent = Ping;\nexport type ClientToolCallEvent = ClientToolCallMessage;\nexport type VadScoreEvent = VadScore;\nexport type MCPToolCallClientEvent = McpToolCall;\nexport type AgentResponseCorrectionEvent = AgentResponseCorrection;\nexport type AgentToolRequestEvent = AgentToolRequestClientEvent;\nexport type AgentToolResponseEvent = AgentToolResponseClientEvent;\nexport type ConversationMetadataEvent = ConversationMetadata;\nexport type AsrInitiationMetadataEvent = AsrMetadataEvent;\nexport type MCPConnectionStatusEvent = McpConnectionStatusClientEvent;\nexport type AgentChatResponsePartEvent = AgentChatResponsePartClientEvent;\nexport type ErrorMessageEvent = ErrorMessage;\n\nexport type IncomingSocketEvent =\n  | UserTranscriptionEvent\n  | AgentResponseEvent\n  | AgentResponseCorrectionEvent\n  | AgentAudioEvent\n  | InterruptionEvent\n  | InternalTentativeAgentResponseEvent\n  | ConfigEvent\n  | PingEvent\n  | ClientToolCallEvent\n  | VadScoreEvent\n  | MCPToolCallClientEvent\n  | AgentToolRequestEvent\n  | AgentToolResponseEvent\n  | ConversationMetadataEvent\n  | AsrInitiationMetadataEvent\n  | MCPConnectionStatusEvent\n  | AgentChatResponsePartEvent\n  | ErrorMessageEvent;\n\n// Compatibility layer - outgoing events\nexport type PongEvent = Outgoing.PongClientToOrchestratorEvent;\nexport type UserAudioEvent = Outgoing.UserAudio;\nexport type UserFeedbackEvent = Outgoing.UserFeedbackClientToOrchestratorEvent;\nexport type ClientToolResultEvent =\n  Outgoing.ClientToolResultClientToOrchestratorEvent;\nexport type InitiationClientDataEvent =\n  Outgoing.ConversationInitiationClientToOrchestratorEvent;\nexport type ContextualUpdateEvent =\n  Outgoing.ContextualUpdateClientToOrchestratorEvent;\nexport type UserMessageEvent = Outgoing.UserMessageClientToOrchestratorEvent;\nexport type UserActivityEvent = Outgoing.UserActivityClientToOrchestratorEvent;\nexport type MCPToolApprovalResultEvent =\n  Outgoing.McpToolApprovalResultClientToOrchestratorEvent;\n\nexport type OutgoingSocketEvent =\n  | PongEvent\n  | UserAudioEvent\n  | InitiationClientDataEvent\n  | UserFeedbackEvent\n  | ClientToolResultEvent\n  | ContextualUpdateEvent\n  | UserMessageEvent\n  | UserActivityEvent\n  | MCPToolApprovalResultEvent;\n\nexport function isValidSocketEvent(event: any): event is IncomingSocketEvent {\n  return !!event.type;\n}\n","import type { SessionConfig } from \"./BaseConnection\";\nimport type { InitiationClientDataEvent } from \"./events\";\n\nexport const CONVERSATION_INITIATION_CLIENT_DATA_TYPE =\n  \"conversation_initiation_client_data\";\n\nexport function constructOverrides(\n  config: SessionConfig\n): InitiationClientDataEvent {\n  const overridesEvent: InitiationClientDataEvent = {\n    type: CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n  };\n\n  if (config.overrides) {\n    overridesEvent.conversation_config_override = {\n      agent: {\n        prompt: config.overrides.agent?.prompt,\n        first_message: config.overrides.agent?.firstMessage,\n        language: config.overrides.agent?.language,\n      },\n      tts: {\n        voice_id: config.overrides.tts?.voiceId,\n      },\n      conversation: {\n        text_only: config.overrides.conversation?.textOnly,\n      },\n    };\n  }\n\n  if (config.customLlmExtraBody) {\n    overridesEvent.custom_llm_extra_body = config.customLlmExtraBody;\n  }\n\n  if (config.dynamicVariables) {\n    overridesEvent.dynamic_variables = config.dynamicVariables;\n  }\n\n  if (config.userId) {\n    overridesEvent.user_id = config.userId;\n  }\n\n  if (config.overrides?.client) {\n    overridesEvent.source_info = {\n      source: config.overrides.client.source,\n      version: config.overrides.client.version,\n    };\n  }\n\n  return overridesEvent;\n}\n","import {\n  BaseConnection,\n  type SessionConfig,\n  type FormatConfig,\n  parseFormat,\n} from \"./BaseConnection\";\nimport { PACKAGE_VERSION } from \"../version\";\nimport {\n  type ConfigEvent,\n  isValidSocketEvent,\n  type OutgoingSocketEvent,\n} from \"./events\";\nimport { constructOverrides } from \"./overrides\";\n\nconst MAIN_PROTOCOL = \"convai\";\nconst WSS_API_ORIGIN = \"wss://api.elevenlabs.io\";\nconst WSS_API_PATHNAME = \"/v1/convai/conversation?agent_id=\";\n\nexport class WebSocketConnection extends BaseConnection {\n  public readonly conversationId: string;\n  public readonly inputFormat: FormatConfig;\n  public readonly outputFormat: FormatConfig;\n\n  private constructor(\n    private readonly socket: WebSocket,\n    conversationId: string,\n    inputFormat: FormatConfig,\n    outputFormat: FormatConfig\n  ) {\n    super();\n    this.conversationId = conversationId;\n    this.inputFormat = inputFormat;\n    this.outputFormat = outputFormat;\n\n    this.socket.addEventListener(\"error\", event => {\n      // In case the error event is followed by a close event, we want the\n      // latter to be the one that disconnects the session as it contains more\n      // useful information.\n      setTimeout(\n        () =>\n          this.disconnect({\n            reason: \"error\",\n            message: \"The connection was closed due to a socket error.\",\n            context: event,\n          }),\n        0\n      );\n    });\n\n    this.socket.addEventListener(\"close\", event => {\n      this.disconnect(\n        event.code === 1000\n          ? {\n              reason: \"agent\",\n              context: event,\n            }\n          : {\n              reason: \"error\",\n              message:\n                event.reason || \"The connection was closed by the server.\",\n              context: event,\n            }\n      );\n    });\n\n    this.socket.addEventListener(\"message\", event => {\n      try {\n        const parsedEvent = JSON.parse(event.data);\n        if (!isValidSocketEvent(parsedEvent)) {\n          this.debug({\n            type: \"invalid_event\",\n            message: \"Received invalid socket event\",\n            data: event.data,\n          });\n          return;\n        }\n        this.handleMessage(parsedEvent);\n      } catch (error) {\n        this.debug({\n          type: \"parsing_error\",\n          message: \"Failed to parse socket message\",\n          error: error instanceof Error ? error.message : String(error),\n          data: event.data,\n        });\n      }\n    });\n  }\n\n  public static async create(\n    config: SessionConfig\n  ): Promise<WebSocketConnection> {\n    let socket: WebSocket | null = null;\n\n    try {\n      const origin = config.origin ?? WSS_API_ORIGIN;\n      let url: string;\n\n      const version = config.overrides?.client?.version || PACKAGE_VERSION;\n      const source = config.overrides?.client?.source || \"js_sdk\";\n\n      if (config.signedUrl) {\n        const separator = config.signedUrl.includes(\"?\") ? \"&\" : \"?\";\n        url = `${config.signedUrl}${separator}source=${source}&version=${version}`;\n      } else {\n        url = `${origin}${WSS_API_PATHNAME}${config.agentId}&source=${source}&version=${version}`;\n      }\n\n      const protocols = [MAIN_PROTOCOL];\n      if (config.authorization) {\n        protocols.push(`bearer.${config.authorization}`);\n      }\n      socket = new WebSocket(url, protocols);\n\n      const conversationConfig = await new Promise<\n        ConfigEvent[\"conversation_initiation_metadata_event\"]\n      >((resolve, reject) => {\n        socket!.addEventListener(\n          \"open\",\n          () => {\n            const overridesEvent = constructOverrides(config);\n\n            socket?.send(JSON.stringify(overridesEvent));\n          },\n          { once: true }\n        );\n\n        socket!.addEventListener(\"error\", event => {\n          // In case the error event is followed by a close event, we want the\n          // latter to be the one that rejects the promise as it contains more\n          // useful information.\n          setTimeout(() => reject(event), 0);\n        });\n\n        socket!.addEventListener(\"close\", reject);\n\n        socket!.addEventListener(\n          \"message\",\n          (event: MessageEvent) => {\n            const message = JSON.parse(event.data);\n\n            if (!isValidSocketEvent(message)) {\n              return;\n            }\n\n            if (message.type === \"conversation_initiation_metadata\") {\n              resolve(message.conversation_initiation_metadata_event);\n            } else {\n              console.warn(\n                \"First received message is not conversation metadata.\"\n              );\n            }\n          },\n          { once: true }\n        );\n      });\n\n      const {\n        conversation_id,\n        agent_output_audio_format,\n        user_input_audio_format,\n      } = conversationConfig;\n\n      const inputFormat = parseFormat(user_input_audio_format ?? \"pcm_16000\");\n      const outputFormat = parseFormat(agent_output_audio_format);\n\n      return new WebSocketConnection(\n        socket,\n        conversation_id,\n        inputFormat,\n        outputFormat\n      );\n    } catch (error) {\n      socket?.close();\n      throw error;\n    }\n  }\n\n  public close() {\n    this.socket.close();\n  }\n\n  public sendMessage(message: OutgoingSocketEvent) {\n    this.socket.send(JSON.stringify(message));\n  }\n\n  public async setMicMuted(isMuted: boolean): Promise<void> {\n    console.warn(\n      `WebSocket connection setMicMuted called with ${isMuted}, but this is handled by VoiceConversation`\n    );\n  }\n}\n","export function arrayBufferToBase64(b: ArrayBufferLike) {\n  const buffer = new Uint8Array(b);\n  // @ts-ignore\n  const base64Data = window.btoa(String.fromCharCode(...buffer));\n  return base64Data;\n}\n\nexport function base64ToArrayBuffer(base64: string): ArrayBuffer {\n  const binaryString = window.atob(base64);\n  const len = binaryString.length;\n  const bytes = new Uint8Array(len);\n  for (let i = 0; i < len; i++) {\n    bytes[i] = binaryString.charCodeAt(i);\n  }\n  return bytes.buffer;\n}\n","const URLCache = new Map<string, string>();\n\nexport function createWorkletModuleLoader(name: string, sourceCode: string) {\n  return async (worklet: AudioWorklet, path?: string) => {\n    const cachedUrl = URLCache.get(name);\n    if (cachedUrl) {\n      return worklet.addModule(cachedUrl);\n    }\n\n    // If a path is provided, use it directly (CSP-friendly approach)\n    if (path) {\n      try {\n        await worklet.addModule(path);\n        URLCache.set(name, path);\n        return;\n      } catch (error) {\n        throw new Error(\n          `Failed to load the ${name} worklet module from path: ${path}. Error: ${error}`\n        );\n      }\n    }\n\n    const blob = new Blob([sourceCode], { type: \"application/javascript\" });\n    const blobURL = URL.createObjectURL(blob);\n    try {\n      await worklet.addModule(blobURL);\n      URLCache.set(name, blobURL);\n      return;\n    } catch {\n      URL.revokeObjectURL(blobURL);\n    }\n\n    try {\n      // Attempting to start a conversation in Safari inside an iframe will\n      // throw a CORS error because the blob:// protocol is considered\n      // cross-origin. In such cases, fall back to using a base64 data URL:\n      const base64 = btoa(sourceCode);\n      const moduleURL = `data:application/javascript;base64,${base64}`;\n      await worklet.addModule(moduleURL);\n      URLCache.set(name, moduleURL);\n    } catch (error) {\n      throw new Error(\n        `Failed to load the ${name} worklet module. Make sure the browser supports AudioWorklets. If you are using a strict CSP, you may need to self-host the worklet files.`\n      );\n    }\n  };\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadRawAudioProcessor = createWorkletModuleLoader(\n  \"rawAudioProcessor\",\n  // language=JavaScript\n  `/*\n * ulaw encoding logic taken from the wavefile library\n * https://github.com/rochars/wavefile/blob/master/lib/codecs/mulaw.js\n * USED BY @elevenlabs/client\n */\n\nconst BIAS = 0x84;\nconst CLIP = 32635;\nconst encodeTable = [\n  0,0,1,1,2,2,2,2,3,3,3,3,3,3,3,3,\n  4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,\n  5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n  5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7\n];\n\nfunction encodeSample(sample) {\n  let sign;\n  let exponent;\n  let mantissa;\n  let muLawSample;\n  sign = (sample >> 8) & 0x80;\n  if (sign !== 0) sample = -sample;\n  sample = sample + BIAS;\n  if (sample > CLIP) sample = CLIP;\n  exponent = encodeTable[(sample>>7) & 0xFF];\n  mantissa = (sample >> (exponent+3)) & 0x0F;\n  muLawSample = ~(sign | (exponent << 4) | mantissa);\n  \n  return muLawSample;\n}\n\nclass RawAudioProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n              \n    this.port.onmessage = ({ data }) => {\n      switch (data.type) {\n        case \"setFormat\":\n          this.isMuted = false;\n          this.buffer = []; // Initialize an empty buffer\n          this.bufferSize = data.sampleRate / 4;\n          this.format = data.format;\n\n          if (globalThis.LibSampleRate && sampleRate !== data.sampleRate) {\n            globalThis.LibSampleRate.create(1, sampleRate, data.sampleRate).then(resampler => {\n              this.resampler = resampler;\n            });\n          }\n          break;\n        case \"setMuted\":\n          this.isMuted = data.isMuted;\n          break;\n      }\n    };\n  }\n  process(inputs) {\n    if (!this.buffer) {\n      return true;\n    }\n    \n    const input = inputs[0]; // Get the first input node\n    if (input.length > 0) {\n      let channelData = input[0]; // Get the first channel's data\n\n      // Resample the audio if necessary\n      if (this.resampler) {\n        channelData = this.resampler.full(channelData);\n      }\n\n      // Add channel data to the buffer\n      this.buffer.push(...channelData);\n      // Get max volume \n      let sum = 0.0;\n      for (let i = 0; i < channelData.length; i++) {\n        sum += channelData[i] * channelData[i];\n      }\n      const maxVolume = Math.sqrt(sum / channelData.length);\n      // Check if buffer size has reached or exceeded the threshold\n      if (this.buffer.length >= this.bufferSize) {\n        const float32Array = this.isMuted \n          ? new Float32Array(this.buffer.length)\n          : new Float32Array(this.buffer);\n\n        let encodedArray = this.format === \"ulaw\"\n          ? new Uint8Array(float32Array.length)\n          : new Int16Array(float32Array.length);\n\n        // Iterate through the Float32Array and convert each sample to PCM16\n        for (let i = 0; i < float32Array.length; i++) {\n          // Clamp the value to the range [-1, 1]\n          let sample = Math.max(-1, Math.min(1, float32Array[i]));\n\n          // Scale the sample to the range [-32768, 32767]\n          let value = sample < 0 ? sample * 32768 : sample * 32767;\n          if (this.format === \"ulaw\") {\n            value = encodeSample(Math.round(value));\n          }\n\n          encodedArray[i] = value;\n        }\n\n        // Send the buffered data to the main script\n        this.port.postMessage([encodedArray, maxVolume]);\n\n        // Clear the buffer after sending\n        this.buffer = [];\n      }\n    }\n    return true; // Continue processing\n  }\n}\nregisterProcessor(\"rawAudioProcessor\", RawAudioProcessor);\n`\n);\n","import {\n  BaseConnection,\n  type SessionConfig,\n  type FormatConfig,\n  parseFormat,\n} from \"./BaseConnection\";\nimport { PACKAGE_VERSION } from \"../version\";\nimport { isValidSocketEvent, type OutgoingSocketEvent } from \"./events\";\nimport {\n  Room,\n  RoomEvent,\n  Track,\n  ConnectionState,\n  createLocalAudioTrack,\n} from \"livekit-client\";\nimport type {\n  RemoteAudioTrack,\n  Participant,\n  TrackPublication,\n  RemoteParticipant,\n} from \"livekit-client\";\nimport {\n  constructOverrides,\n  CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n} from \"./overrides\";\nimport { arrayBufferToBase64 } from \"./audio\";\nimport { loadRawAudioProcessor } from \"./rawAudioProcessor.generated\";\n\nconst DEFAULT_LIVEKIT_WS_URL = \"wss://livekit.rtc.elevenlabs.io\";\nconst HTTPS_API_ORIGIN = \"https://api.elevenlabs.io\";\n\n// Convert WSS origin to HTTPS for API calls\nfunction convertWssToHttps(origin: string): string {\n  return origin.replace(/^wss:\\/\\//, \"https://\");\n}\n\nexport type ConnectionConfig = SessionConfig & {\n  onDebug?: (info: unknown) => void;\n};\n\nexport class WebRTCConnection extends BaseConnection {\n  public conversationId: string;\n  public readonly inputFormat: FormatConfig;\n  public readonly outputFormat: FormatConfig;\n\n  private room: Room;\n  private isConnected = false;\n  private audioEventId = 1;\n  private audioCaptureContext: AudioContext | null = null;\n  private audioElements: HTMLAudioElement[] = [];\n  private outputDeviceId: string | null = null;\n\n  private outputAnalyser: AnalyserNode | null = null;\n  private outputFrequencyData: Uint8Array<ArrayBuffer> | null = null;\n\n  private constructor(\n    room: Room,\n    conversationId: string,\n    inputFormat: FormatConfig,\n    outputFormat: FormatConfig,\n    config: { onDebug?: (info: unknown) => void } = {}\n  ) {\n    super(config);\n    this.room = room;\n    this.conversationId = conversationId;\n    this.inputFormat = inputFormat;\n    this.outputFormat = outputFormat;\n\n    this.setupRoomEventListeners();\n  }\n\n  public static async create(\n    config: ConnectionConfig\n  ): Promise<WebRTCConnection> {\n    let conversationToken: string;\n\n    // Handle different authentication scenarios\n    if (\"conversationToken\" in config && config.conversationToken) {\n      // Direct token provided\n      conversationToken = config.conversationToken;\n    } else if (\"agentId\" in config && config.agentId) {\n      // Agent ID provided - fetch token from API\n      try {\n        const version = config.overrides?.client?.version || PACKAGE_VERSION;\n        const source = config.overrides?.client?.source || \"js_sdk\";\n        const configOrigin = config.origin ?? HTTPS_API_ORIGIN;\n        const origin = convertWssToHttps(configOrigin); //origin is wss, not https\n        const url = `${origin}/v1/convai/conversation/token?agent_id=${config.agentId}&source=${source}&version=${version}`;\n        const response = await fetch(url);\n\n        if (!response.ok) {\n          throw new Error(\n            `ElevenLabs API returned ${response.status} ${response.statusText}`\n          );\n        }\n\n        const data = await response.json();\n        conversationToken = data.token;\n\n        if (!conversationToken) {\n          throw new Error(\"No conversation token received from API\");\n        }\n      } catch (error) {\n        let msg = error instanceof Error ? error.message : String(error);\n        if (error instanceof Error && error.message.includes(\"401\")) {\n          msg =\n            \"Your agent has authentication enabled, but no signed URL or conversation token was provided.\";\n        }\n\n        throw new Error(\n          `Failed to fetch conversation token for agent ${config.agentId}: ${msg}`\n        );\n      }\n    } else {\n      throw new Error(\n        \"Either conversationToken or agentId is required for WebRTC connection\"\n      );\n    }\n\n    const room = new Room();\n\n    try {\n      // Create connection instance first to set up event listeners\n      const conversationId = `room_${Date.now()}`;\n      const inputFormat = parseFormat(\"pcm_48000\");\n      const outputFormat = parseFormat(\"pcm_48000\");\n      const connection = new WebRTCConnection(\n        room,\n        conversationId,\n        inputFormat,\n        outputFormat,\n        config\n      );\n\n      // Use configurable LiveKit URL or default if not provided\n      const livekitUrl = config.livekitUrl || DEFAULT_LIVEKIT_WS_URL;\n\n      // Connect to the LiveKit room and wait for the Connected event\n      await room.connect(livekitUrl, conversationToken);\n\n      // Wait for the Connected event to ensure isConnected is true\n      await new Promise<void>(resolve => {\n        if (connection.isConnected) {\n          resolve();\n        } else {\n          const onConnected = () => {\n            room.off(RoomEvent.Connected, onConnected);\n            resolve();\n          };\n          room.on(RoomEvent.Connected, onConnected);\n        }\n      });\n\n      if (room.name) {\n        connection.conversationId =\n          room.name.match(/(conv_[a-zA-Z0-9]+)/)?.[0] || room.name;\n      }\n\n      // Enable microphone and send overrides\n      await room.localParticipant.setMicrophoneEnabled(true);\n\n      const overridesEvent = constructOverrides(config);\n\n      connection.debug({\n        type: CONVERSATION_INITIATION_CLIENT_DATA_TYPE,\n        message: overridesEvent,\n      });\n\n      await connection.sendMessage(overridesEvent);\n\n      return connection;\n    } catch (error) {\n      await room.disconnect();\n      throw error;\n    }\n  }\n\n  private setupRoomEventListeners() {\n    this.room.on(RoomEvent.Connected, async () => {\n      this.isConnected = true;\n      console.info(\"WebRTC room connected\");\n    });\n\n    this.room.on(RoomEvent.Disconnected, reason => {\n      this.isConnected = false;\n      this.disconnect({\n        reason: \"agent\",\n        context: new CloseEvent(\"close\", { reason: reason?.toString() }),\n      });\n    });\n\n    this.room.on(RoomEvent.ConnectionStateChanged, state => {\n      if (state === ConnectionState.Disconnected) {\n        this.isConnected = false;\n        this.disconnect({\n          reason: \"error\",\n          message: `LiveKit connection state changed to ${state}`,\n          context: new Event(\"connection_state_changed\"),\n        });\n      }\n    });\n\n    // Handle incoming data messages\n    this.room.on(\n      RoomEvent.DataReceived,\n      (payload: Uint8Array, _participant) => {\n        try {\n          const message = JSON.parse(new TextDecoder().decode(payload));\n\n          // Filter out audio messages for WebRTC - they're handled via audio tracks\n          if (message.type === \"audio\") {\n            return;\n          }\n\n          if (isValidSocketEvent(message)) {\n            this.handleMessage(message);\n          } else {\n            console.warn(\"Invalid socket event received:\", message);\n          }\n        } catch (error) {\n          console.warn(\"Failed to parse incoming data message:\", error);\n          console.warn(\"Raw payload:\", new TextDecoder().decode(payload));\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.TrackSubscribed,\n      async (\n        track: Track,\n        _publication: TrackPublication,\n        participant: Participant\n      ) => {\n        if (\n          track.kind === Track.Kind.Audio &&\n          participant.identity.includes(\"agent\")\n        ) {\n          // Play the audio track\n          const remoteAudioTrack = track as RemoteAudioTrack;\n          const audioElement = remoteAudioTrack.attach();\n          audioElement.autoplay = true;\n          audioElement.controls = false;\n\n          // Set output device if one was previously selected\n          if (this.outputDeviceId && audioElement.setSinkId) {\n            try {\n              await audioElement.setSinkId(this.outputDeviceId);\n            } catch (error) {\n              console.warn(\n                \"Failed to set output device for new audio element:\",\n                error\n              );\n            }\n          }\n\n          // Add to DOM (hidden) to ensure it plays\n          audioElement.style.display = \"none\";\n          document.body.appendChild(audioElement);\n\n          // Store reference for volume control\n          this.audioElements.push(audioElement);\n\n          // Apply current volume if it exists (for when volume was set before audio track arrived)\n          if (this.audioElements.length === 1) {\n            // First audio element - trigger a callback to sync with current volume\n            this.onDebug?.({ type: \"audio_element_ready\" });\n          }\n\n          // Set up audio capture for onAudio callback\n          await this.setupAudioCapture(remoteAudioTrack);\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.ActiveSpeakersChanged,\n      async (speakers: Participant[]) => {\n        if (speakers.length > 0) {\n          this.updateMode(\n            speakers[0].identity.startsWith(\"agent\") ? \"speaking\" : \"listening\"\n          );\n        } else {\n          this.updateMode(\"listening\");\n        }\n      }\n    );\n\n    this.room.on(\n      RoomEvent.ParticipantDisconnected,\n      (participant: RemoteParticipant) => {\n        if (participant.identity?.startsWith(\"agent\")) {\n          this.disconnect({\n            reason: \"agent\",\n            context: new CloseEvent(\"close\", { reason: \"agent disconnected\" }),\n          });\n        }\n      }\n    );\n  }\n\n  public close() {\n    if (this.isConnected) {\n      try {\n        // Explicitly stop all local tracks before disconnecting to ensure microphone is released\n        this.room.localParticipant.audioTrackPublications.forEach(\n          publication => {\n            if (publication.track) {\n              publication.track.stop();\n            }\n          }\n        );\n      } catch (error) {\n        console.warn(\"Error stopping local tracks:\", error);\n      }\n\n      // Clean up audio capture context (non-blocking)\n      if (this.audioCaptureContext) {\n        this.audioCaptureContext.close().catch(error => {\n          console.warn(\"Error closing audio capture context:\", error);\n        });\n        this.audioCaptureContext = null;\n      }\n\n      // Clean up audio elements\n      this.audioElements.forEach(element => {\n        if (element.parentNode) {\n          element.parentNode.removeChild(element);\n        }\n      });\n      this.audioElements = [];\n\n      this.room.disconnect();\n    }\n  }\n\n  public async sendMessage(message: OutgoingSocketEvent) {\n    if (!this.isConnected || !this.room.localParticipant) {\n      console.warn(\n        \"Cannot send message: room not connected or no local participant\"\n      );\n      return;\n    }\n\n    // In WebRTC mode, audio is sent via published tracks, not data messages\n    if (\"user_audio_chunk\" in message) {\n      // Ignore audio data messages - audio flows through WebRTC tracks\n      return;\n    }\n\n    try {\n      const encoder = new TextEncoder();\n      const data = encoder.encode(JSON.stringify(message));\n\n      await this.room.localParticipant.publishData(data, { reliable: true });\n    } catch (error) {\n      this.debug({\n        type: \"send_message_error\",\n        message: {\n          message,\n          error,\n        },\n      });\n      console.error(\"Failed to send message via WebRTC:\", error);\n    }\n  }\n\n  // Get the room instance for advanced usage\n  public getRoom(): Room {\n    return this.room;\n  }\n\n  public async setMicMuted(isMuted: boolean): Promise<void> {\n    if (!this.isConnected || !this.room.localParticipant) {\n      console.warn(\n        \"Cannot set microphone muted: room not connected or no local participant\"\n      );\n      return;\n    }\n\n    // Get the microphone track publication\n    const micTrackPublication = this.room.localParticipant.getTrackPublication(\n      Track.Source.Microphone\n    );\n\n    if (micTrackPublication?.track) {\n      try {\n        // Use LiveKit's built-in track muting\n        if (isMuted) {\n          await micTrackPublication.track.mute();\n        } else {\n          await micTrackPublication.track.unmute();\n        }\n      } catch (_error) {\n        // If track muting fails, fall back to participant-level control\n        await this.room.localParticipant.setMicrophoneEnabled(!isMuted);\n      }\n    } else {\n      // No track found, use participant-level control directly\n      await this.room.localParticipant.setMicrophoneEnabled(!isMuted);\n    }\n  }\n\n  private async setupAudioCapture(track: RemoteAudioTrack) {\n    try {\n      // Create audio context for processing\n      const audioContext = new AudioContext();\n      this.audioCaptureContext = audioContext;\n\n      // Create analyser for frequency data\n      this.outputAnalyser = audioContext.createAnalyser();\n      this.outputAnalyser.fftSize = 2048;\n      this.outputAnalyser.smoothingTimeConstant = 0.8;\n\n      // Create MediaStream from the track\n      const mediaStream = new MediaStream([track.mediaStreamTrack]);\n\n      // Create audio source from the stream\n      const source = audioContext.createMediaStreamSource(mediaStream);\n\n      // Connect source to analyser\n      source.connect(this.outputAnalyser);\n\n      await loadRawAudioProcessor(audioContext.audioWorklet);\n      const worklet = new AudioWorkletNode(audioContext, \"rawAudioProcessor\");\n\n      // Connect analyser to worklet for processing\n      this.outputAnalyser.connect(worklet);\n\n      // Configure the processor for the output format\n      worklet.port.postMessage({\n        type: \"setFormat\",\n        format: this.outputFormat.format,\n        sampleRate: this.outputFormat.sampleRate,\n      });\n\n      // Handle processed audio data\n      worklet.port.onmessage = (event: MessageEvent) => {\n        const [audioData, maxVolume] = event.data;\n\n        // Only send audio if there's significant volume (not just silence)\n        const volumeThreshold = 0.01;\n\n        if (maxVolume > volumeThreshold) {\n          // Convert to base64\n          const base64Audio = arrayBufferToBase64(audioData.buffer);\n\n          // Use sequential event ID for proper feedback tracking\n          const eventId = this.audioEventId++;\n\n          // Trigger the onAudio callback by simulating an audio event\n          this.handleMessage({\n            type: \"audio\",\n            audio_event: {\n              audio_base_64: base64Audio,\n              event_id: eventId,\n            },\n          });\n        }\n      };\n\n      // Connect the audio processing chain\n      source.connect(worklet);\n    } catch (error) {\n      console.warn(\"Failed to set up audio capture:\", error);\n    }\n  }\n\n  public setAudioVolume(volume: number) {\n    this.audioElements.forEach(element => {\n      element.volume = volume;\n    });\n  }\n\n  public async setAudioOutputDevice(deviceId: string): Promise<void> {\n    if (!(\"setSinkId\" in HTMLAudioElement.prototype)) {\n      throw new Error(\"setSinkId is not supported in this browser\");\n    }\n\n    // Set output device for all existing audio elements\n    const promises = this.audioElements.map(async element => {\n      try {\n        await element.setSinkId(deviceId);\n      } catch (error) {\n        console.error(\"Failed to set sink ID for audio element:\", error);\n        throw error;\n      }\n    });\n\n    await Promise.all(promises);\n\n    // Store the device ID for future audio elements\n    this.outputDeviceId = deviceId;\n  }\n\n  public async setAudioInputDevice(deviceId: string): Promise<void> {\n    if (!this.isConnected || !this.room.localParticipant) {\n      throw new Error(\n        \"Cannot change input device: room not connected or no local participant\"\n      );\n    }\n\n    try {\n      // Get the current microphone track publication\n      const currentMicTrackPublication =\n        this.room.localParticipant.getTrackPublication(Track.Source.Microphone);\n\n      // Stop the current microphone track if it exists\n      if (currentMicTrackPublication?.track) {\n        await currentMicTrackPublication.track.stop();\n        await this.room.localParticipant.unpublishTrack(\n          currentMicTrackPublication.track\n        );\n      }\n\n      // Create constraints for the new input device\n      const audioConstraints: MediaTrackConstraints = {\n        deviceId: { exact: deviceId },\n        echoCancellation: true,\n        noiseSuppression: true,\n        autoGainControl: true,\n        channelCount: { ideal: 1 },\n      };\n\n      // Create new audio track with the specified device\n      const audioTrack = await createLocalAudioTrack(audioConstraints);\n\n      // Publish the new microphone track\n      await this.room.localParticipant.publishTrack(audioTrack, {\n        name: \"microphone\",\n        source: Track.Source.Microphone,\n      });\n    } catch (error) {\n      console.error(\"Failed to change input device:\", error);\n\n      // Try to re-enable default microphone on failure\n      try {\n        await this.room.localParticipant.setMicrophoneEnabled(true);\n      } catch (recoveryError) {\n        console.error(\n          \"Failed to recover microphone after device switch error:\",\n          recoveryError\n        );\n      }\n\n      throw error;\n    }\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array<ArrayBuffer> | null {\n    if (!this.outputAnalyser) return null;\n\n    this.outputFrequencyData ??= new Uint8Array(\n      this.outputAnalyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.outputAnalyser.getByteFrequencyData(this.outputFrequencyData);\n    return this.outputFrequencyData;\n  }\n}\n","import type {\n  BaseConnection,\n  SessionConfig,\n  ConnectionType,\n} from \"./BaseConnection\";\nimport { WebSocketConnection } from \"./WebSocketConnection\";\nimport { WebRTCConnection } from \"./WebRTCConnection\";\n\nfunction determineConnectionType(config: SessionConfig): ConnectionType {\n  // If connectionType is explicitly specified, use it\n  if (config.connectionType) {\n    return config.connectionType;\n  }\n\n  // If conversationToken is provided, use WebRTC\n  if (\"conversationToken\" in config && config.conversationToken) {\n    return \"webrtc\";\n  }\n\n  // Default to WebSocket for backward compatibility\n  return \"websocket\";\n}\n\nexport async function createConnection(\n  config: SessionConfig\n): Promise<BaseConnection> {\n  const connectionType = determineConnectionType(config);\n\n  switch (connectionType) {\n    case \"websocket\":\n      return WebSocketConnection.create(config);\n    case \"webrtc\":\n      return WebRTCConnection.create(config);\n    default:\n      throw new Error(`Unknown connection type: ${connectionType}`);\n  }\n}\n","export function isIosDevice() {\n  return (\n    [\n      \"iPad Simulator\",\n      \"iPhone Simulator\",\n      \"iPod Simulator\",\n      \"iPad\",\n      \"iPhone\",\n      \"iPod\",\n    ].includes(navigator.platform) ||\n    // iPad on iOS 13 detection\n    (navigator.userAgent.includes(\"Mac\") && \"ontouchend\" in document)\n  );\n}\n\nexport function isAndroidDevice() {\n  return /android/i.test(navigator.userAgent);\n}\n","import { isAndroidDevice, isIosDevice } from \"./compatibility\";\nimport type { DelayConfig } from \"./connection\";\n\nexport async function applyDelay(\n  delayConfig: DelayConfig = {\n    default: 0,\n    // Give the Android AudioManager enough time to switch to the correct audio mode\n    android: 3_000,\n  }\n) {\n  let delay = delayConfig.default;\n  if (isAndroidDevice()) {\n    delay = delayConfig.android ?? delay;\n  } else if (isIosDevice()) {\n    delay = delayConfig.ios ?? delay;\n  }\n\n  if (delay > 0) {\n    await new Promise(resolve => setTimeout(resolve, delay));\n  }\n}\n","import { createConnection } from \"./utils/ConnectionFactory\";\nimport type { BaseConnection } from \"./utils/BaseConnection\";\nimport { applyDelay } from \"./utils/applyDelay\";\nimport { BaseConversation, type PartialOptions } from \"./BaseConversation\";\n\nexport class TextConversation extends BaseConversation {\n  public static async startSession(\n    options: PartialOptions\n  ): Promise<TextConversation> {\n    const fullOptions = BaseConversation.getFullOptions(options);\n\n    if (fullOptions.onStatusChange) {\n      fullOptions.onStatusChange({ status: \"connecting\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n    if (fullOptions.onModeChange) {\n      fullOptions.onModeChange({ mode: \"listening\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n\n    let connection: BaseConnection | null = null;\n    try {\n      await applyDelay(fullOptions.connectionDelay);\n      connection = await createConnection(options);\n      return new TextConversation(fullOptions, connection);\n    } catch (error) {\n      if (fullOptions.onStatusChange) {\n        fullOptions.onStatusChange({ status: \"disconnected\" });\n      }\n      connection?.close();\n      throw error;\n    }\n  }\n}\n","import { loadRawAudioProcessor } from \"./rawAudioProcessor.generated\";\nimport type { FormatConfig } from \"./connection\";\nimport { isIosDevice } from \"./compatibility\";\nimport type { AudioWorkletConfig } from \"../BaseConversation\";\n\nexport type InputConfig = {\n  preferHeadphonesForIosDevices?: boolean;\n  inputDeviceId?: string;\n};\n\nconst LIBSAMPLERATE_JS =\n  \"https://cdn.jsdelivr.net/npm/@alexanderolsen/libsamplerate-js@2.1.2/dist/libsamplerate.worklet.js\";\n\nconst defaultConstraints = {\n  echoCancellation: true,\n  noiseSuppression: true,\n  // Automatic gain control helps maintain a steady volume level with microphones: https://developer.mozilla.org/en-US/docs/Web/API/MediaTrackSettings/autoGainControl\n  autoGainControl: true,\n  // Mono audio for better echo cancellation\n  channelCount: { ideal: 1 },\n};\n\nexport class Input {\n  public static async create({\n    sampleRate,\n    format,\n    preferHeadphonesForIosDevices,\n    inputDeviceId,\n    workletPaths,\n    libsampleratePath,\n  }: FormatConfig & InputConfig & AudioWorkletConfig): Promise<Input> {\n    let context: AudioContext | null = null;\n    let inputStream: MediaStream | null = null;\n\n    try {\n      const options: MediaTrackConstraints = {\n        sampleRate: { ideal: sampleRate },\n        ...defaultConstraints,\n      };\n\n      if (isIosDevice() && preferHeadphonesForIosDevices) {\n        const availableDevices =\n          await window.navigator.mediaDevices.enumerateDevices();\n        const idealDevice = availableDevices.find(\n          d =>\n            // cautious to include \"bluetooth\" in the search\n            // as might trigger bluetooth speakers\n            d.kind === \"audioinput\" &&\n            [\"airpod\", \"headphone\", \"earphone\"].find(keyword =>\n              d.label.toLowerCase().includes(keyword)\n            )\n        );\n        if (idealDevice) {\n          options.deviceId = { ideal: idealDevice.deviceId };\n        }\n      }\n\n      if (inputDeviceId) {\n        options.deviceId = Input.getDeviceIdConstraint(inputDeviceId);\n      }\n\n      const supportsSampleRateConstraint =\n        navigator.mediaDevices.getSupportedConstraints().sampleRate;\n\n      context = new window.AudioContext(\n        supportsSampleRateConstraint ? { sampleRate } : {}\n      );\n      const analyser = context.createAnalyser();\n      if (!supportsSampleRateConstraint) {\n        // Use custom libsamplerate path if provided, otherwise fallback to CDN\n        const libsamplerateUrl = libsampleratePath || LIBSAMPLERATE_JS;\n        await context.audioWorklet.addModule(libsamplerateUrl);\n      }\n      await loadRawAudioProcessor(\n        context.audioWorklet,\n        workletPaths?.[\"rawAudioProcessor\"]\n      );\n\n      const constraints = { voiceIsolation: true, ...options };\n      inputStream = await navigator.mediaDevices.getUserMedia({\n        audio: constraints,\n      });\n\n      const source = context.createMediaStreamSource(inputStream);\n      const worklet = new AudioWorkletNode(context, \"rawAudioProcessor\");\n      worklet.port.postMessage({ type: \"setFormat\", format, sampleRate });\n\n      source.connect(analyser);\n      analyser.connect(worklet);\n\n      await context.resume();\n\n      return new Input(context, analyser, worklet, inputStream, source);\n    } catch (error) {\n      inputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      context?.close();\n      throw error;\n    }\n  }\n\n  // Use { ideal } on iOS as a defensive measure - some iOS versions may not support { exact } for deviceId constraints\n  private static getDeviceIdConstraint(\n    inputDeviceId?: string\n  ): MediaTrackConstraints[\"deviceId\"] {\n    if (!inputDeviceId) {\n      return undefined;\n    }\n    return isIosDevice() ? { ideal: inputDeviceId } : { exact: inputDeviceId };\n  }\n\n  private constructor(\n    public readonly context: AudioContext,\n    public readonly analyser: AnalyserNode,\n    public readonly worklet: AudioWorkletNode,\n    public inputStream: MediaStream,\n    private mediaStreamSource: MediaStreamAudioSourceNode\n  ) {}\n\n  public async close() {\n    this.inputStream.getTracks().forEach(track => {\n      track.stop();\n    });\n    this.mediaStreamSource.disconnect();\n    await this.context.close();\n  }\n\n  public setMuted(isMuted: boolean) {\n    this.worklet.port.postMessage({ type: \"setMuted\", isMuted });\n  }\n\n  public async setInputDevice(inputDeviceId?: string): Promise<void> {\n    try {\n      // Create new constraints with the specified device or use default\n      const options: MediaTrackConstraints = {\n        ...defaultConstraints,\n      };\n\n      if (inputDeviceId) {\n        options.deviceId = Input.getDeviceIdConstraint(inputDeviceId);\n      }\n      // If inputDeviceId is undefined, don't set deviceId constraint - browser uses default\n\n      const constraints = { voiceIsolation: true, ...options };\n\n      // Get new media stream with the specified device\n      const newInputStream = await navigator.mediaDevices.getUserMedia({\n        audio: constraints,\n      });\n\n      // Stop old tracks and disconnect old source\n      this.inputStream.getTracks().forEach(track => {\n        track.stop();\n      });\n      this.mediaStreamSource.disconnect();\n\n      // Replace the stream and create new source\n      this.inputStream = newInputStream;\n      this.mediaStreamSource =\n        this.context.createMediaStreamSource(newInputStream);\n\n      // Reconnect the audio graph\n      this.mediaStreamSource.connect(this.analyser);\n    } catch (error) {\n      console.error(\"Failed to switch input device:\", error);\n      throw error;\n    }\n  }\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadAudioConcatProcessor = createWorkletModuleLoader(\n  \"audioConcatProcessor\",\n  // language=JavaScript\n  `/*\n * ulaw decoding logic taken from the wavefile library\n * https://github.com/rochars/wavefile/blob/master/lib/codecs/mulaw.js\n * USED BY @elevenlabs/client\n */\n\nconst decodeTable = [0,132,396,924,1980,4092,8316,16764];\n\nfunction decodeSample(muLawSample) {\n  let sign;\n  let exponent;\n  let mantissa;\n  let sample;\n  muLawSample = ~muLawSample;\n  sign = (muLawSample & 0x80);\n  exponent = (muLawSample >> 4) & 0x07;\n  mantissa = muLawSample & 0x0F;\n  sample = decodeTable[exponent] + (mantissa << (exponent+3));\n  if (sign !== 0) sample = -sample;\n\n  return sample;\n}\n\nclass AudioConcatProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.buffers = []; // Initialize an empty buffer\n    this.cursor = 0;\n    this.currentBuffer = null;\n    this.wasInterrupted = false;\n    this.finished = false;\n    \n    this.port.onmessage = ({ data }) => {\n      switch (data.type) {\n        case \"setFormat\":\n          this.format = data.format;\n          break;\n        case \"buffer\":\n          this.wasInterrupted = false;\n          this.buffers.push(\n            this.format === \"ulaw\"\n              ? new Uint8Array(data.buffer)\n              : new Int16Array(data.buffer)\n          );\n          break;\n        case \"interrupt\":\n          this.wasInterrupted = true;\n          break;\n        case \"clearInterrupted\":\n          if (this.wasInterrupted) {\n            this.wasInterrupted = false;\n            this.buffers = [];\n            this.currentBuffer = null;\n          }\n      }\n    };\n  }\n  process(_, outputs) {\n    let finished = false;\n    const output = outputs[0][0];\n    for (let i = 0; i < output.length; i++) {\n      if (!this.currentBuffer) {\n        if (this.buffers.length === 0) {\n          finished = true;\n          break;\n        }\n        this.currentBuffer = this.buffers.shift();\n        this.cursor = 0;\n      }\n\n      let value = this.currentBuffer[this.cursor];\n      if (this.format === \"ulaw\") {\n        value = decodeSample(value);\n      }\n      output[i] = value / 32768;\n      this.cursor++;\n\n      if (this.cursor >= this.currentBuffer.length) {\n        this.currentBuffer = null;\n      }\n    }\n\n    if (this.finished !== finished) {\n      this.finished = finished;\n      this.port.postMessage({ type: \"process\", finished });\n    }\n\n    return true; // Continue processing\n  }\n}\n\nregisterProcessor(\"audioConcatProcessor\", AudioConcatProcessor);\n`\n);\n","import { loadAudioConcatProcessor } from \"./audioConcatProcessor.generated\";\nimport type { FormatConfig } from \"./connection\";\nimport type { AudioWorkletConfig } from \"../BaseConversation\";\n\nexport type OutputConfig = {\n  outputDeviceId?: string;\n};\n\nexport class Output {\n  public static async create({\n    sampleRate,\n    format,\n    outputDeviceId,\n    workletPaths,\n  }: FormatConfig & OutputConfig & AudioWorkletConfig): Promise<Output> {\n    let context: AudioContext | null = null;\n    let audioElement: HTMLAudioElement | null = null;\n    try {\n      context = new AudioContext({ sampleRate });\n      const analyser = context.createAnalyser();\n      const gain = context.createGain();\n\n      // Always create an audio element for device switching capability\n      audioElement = new Audio();\n      audioElement.src = \"\";\n      audioElement.load();\n      audioElement.autoplay = true;\n      audioElement.style.display = \"none\";\n\n      document.body.appendChild(audioElement);\n\n      // Create media stream destination to route audio to the element\n      const destination = context.createMediaStreamDestination();\n      audioElement.srcObject = destination.stream;\n\n      gain.connect(analyser);\n      analyser.connect(destination);\n\n      await loadAudioConcatProcessor(\n        context.audioWorklet,\n        workletPaths?.[\"audioConcatProcessor\"]\n      );\n      const worklet = new AudioWorkletNode(context, \"audioConcatProcessor\");\n      worklet.port.postMessage({ type: \"setFormat\", format });\n      worklet.connect(gain);\n\n      await context.resume();\n\n      // Set initial output device if provided\n      if (outputDeviceId && audioElement.setSinkId) {\n        await audioElement.setSinkId(outputDeviceId);\n      }\n\n      const newOutput = new Output(\n        context,\n        analyser,\n        gain,\n        worklet,\n        audioElement\n      );\n\n      return newOutput;\n    } catch (error) {\n      // Clean up audio element from DOM\n      if (audioElement?.parentNode) {\n        audioElement.parentNode.removeChild(audioElement);\n      }\n      audioElement?.pause();\n      if (context && context.state !== \"closed\") {\n        await context.close();\n      }\n\n      throw error;\n    }\n  }\n\n  private constructor(\n    public readonly context: AudioContext,\n    public readonly analyser: AnalyserNode,\n    public readonly gain: GainNode,\n    public readonly worklet: AudioWorkletNode,\n    public readonly audioElement: HTMLAudioElement\n  ) {}\n\n  public async setOutputDevice(deviceId?: string): Promise<void> {\n    if (!(\"setSinkId\" in HTMLAudioElement.prototype)) {\n      throw new Error(\"setSinkId is not supported in this browser\");\n    }\n\n    // If deviceId is undefined, use empty string which resets to default device\n    await this.audioElement.setSinkId(deviceId || \"\");\n  }\n\n  public async close() {\n    // Remove audio element from DOM\n    if (this.audioElement.parentNode) {\n      this.audioElement.parentNode.removeChild(this.audioElement);\n    }\n    this.audioElement.pause();\n    await this.context.close();\n  }\n}\n","import { arrayBufferToBase64, base64ToArrayBuffer } from \"./utils/audio\";\nimport { Input, type InputConfig } from \"./utils/input\";\nimport { Output } from \"./utils/output\";\nimport { createConnection } from \"./utils/ConnectionFactory\";\nimport type { BaseConnection, FormatConfig } from \"./utils/BaseConnection\";\nimport { WebRTCConnection } from \"./utils/WebRTCConnection\";\nimport type { AgentAudioEvent, InterruptionEvent } from \"./utils/events\";\nimport { applyDelay } from \"./utils/applyDelay\";\nimport {\n  BaseConversation,\n  type Options,\n  type PartialOptions,\n} from \"./BaseConversation\";\nimport { WebSocketConnection } from \"./utils/WebSocketConnection\";\n\nexport class VoiceConversation extends BaseConversation {\n  public static async startSession(\n    options: PartialOptions\n  ): Promise<VoiceConversation> {\n    const fullOptions = BaseConversation.getFullOptions(options);\n\n    if (fullOptions.onStatusChange) {\n      fullOptions.onStatusChange({ status: \"connecting\" });\n    }\n    if (fullOptions.onCanSendFeedbackChange) {\n      fullOptions.onCanSendFeedbackChange({ canSendFeedback: false });\n    }\n\n    let input: Input | null = null;\n    let connection: BaseConnection | null = null;\n    let output: Output | null = null;\n    let preliminaryInputStream: MediaStream | null = null;\n\n    let wakeLock: WakeLockSentinel | null = null;\n    if (options.useWakeLock ?? true) {\n      try {\n        wakeLock = await navigator.wakeLock.request(\"screen\");\n      } catch (_e) {\n        // Wake Lock is not required for the conversation to work\n      }\n    }\n\n    try {\n      // some browsers won't allow calling getSupportedConstraints or enumerateDevices\n      // before getting approval for microphone access\n      preliminaryInputStream = await navigator.mediaDevices.getUserMedia({\n        audio: true,\n      });\n\n      await applyDelay(fullOptions.connectionDelay);\n      connection = await createConnection(options);\n      [input, output] = await Promise.all([\n        Input.create({\n          ...connection.inputFormat,\n          preferHeadphonesForIosDevices: options.preferHeadphonesForIosDevices,\n          inputDeviceId: options.inputDeviceId,\n          workletPaths: options.workletPaths,\n          libsampleratePath: options.libsampleratePath,\n        }),\n        Output.create({\n          ...connection.outputFormat,\n          outputDeviceId: options.outputDeviceId,\n          workletPaths: options.workletPaths,\n        }),\n      ]);\n\n      preliminaryInputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      preliminaryInputStream = null;\n\n      return new VoiceConversation(\n        fullOptions,\n        connection,\n        input,\n        output,\n        wakeLock\n      );\n    } catch (error) {\n      if (fullOptions.onStatusChange) {\n        fullOptions.onStatusChange({ status: \"disconnected\" });\n      }\n      preliminaryInputStream?.getTracks().forEach(track => {\n        track.stop();\n      });\n      connection?.close();\n      await input?.close();\n      await output?.close();\n      try {\n        await wakeLock?.release();\n        wakeLock = null;\n      } catch (_e) {}\n      throw error;\n    }\n  }\n\n  private inputFrequencyData?: Uint8Array<ArrayBuffer>;\n  private outputFrequencyData?: Uint8Array<ArrayBuffer>;\n\n  protected constructor(\n    options: Options,\n    connection: BaseConnection,\n    public input: Input,\n    public output: Output,\n    public wakeLock: WakeLockSentinel | null\n  ) {\n    super(options, connection);\n    this.input.worklet.port.onmessage = this.onInputWorkletMessage;\n    this.output.worklet.port.onmessage = this.onOutputWorkletMessage;\n  }\n\n  protected override async handleEndSession() {\n    await super.handleEndSession();\n    try {\n      await this.wakeLock?.release();\n      this.wakeLock = null;\n    } catch (_e) {}\n\n    await this.input.close();\n    await this.output.close();\n  }\n\n  protected override handleInterruption(event: InterruptionEvent) {\n    super.handleInterruption(event);\n    this.fadeOutAudio();\n  }\n\n  protected override handleAudio(event: AgentAudioEvent) {\n    if (this.lastInterruptTimestamp <= event.audio_event.event_id) {\n      this.options.onAudio?.(event.audio_event.audio_base_64);\n\n      // Only play audio through the output worklet for WebSocket connections\n      // WebRTC connections handle audio playback directly through LiveKit tracks\n      if (!(this.connection instanceof WebRTCConnection)) {\n        this.addAudioBase64Chunk(event.audio_event.audio_base_64);\n      }\n\n      this.currentEventId = event.audio_event.event_id;\n      this.updateCanSendFeedback();\n      this.updateMode(\"speaking\");\n    }\n  }\n\n  private onInputWorkletMessage = (event: MessageEvent): void => {\n    const rawAudioPcmData = event.data[0];\n\n    // TODO: When supported, maxVolume can be used to avoid sending silent audio\n    // const maxVolume = event.data[1];\n\n    if (this.status === \"connected\") {\n      this.connection.sendMessage({\n        user_audio_chunk: arrayBufferToBase64(rawAudioPcmData.buffer),\n      });\n    }\n  };\n\n  private onOutputWorkletMessage = ({ data }: MessageEvent): void => {\n    if (data.type === \"process\") {\n      this.updateMode(data.finished ? \"listening\" : \"speaking\");\n    }\n  };\n\n  private addAudioBase64Chunk = (chunk: string) => {\n    this.output.gain.gain.cancelScheduledValues(\n      this.output.context.currentTime\n    );\n    this.output.gain.gain.value = this.volume;\n    this.output.worklet.port.postMessage({ type: \"clearInterrupted\" });\n    this.output.worklet.port.postMessage({\n      type: \"buffer\",\n      buffer: base64ToArrayBuffer(chunk),\n    });\n  };\n\n  private fadeOutAudio = () => {\n    // mute agent\n    this.updateMode(\"listening\");\n    this.output.worklet.port.postMessage({ type: \"interrupt\" });\n    this.output.gain.gain.exponentialRampToValueAtTime(\n      0.0001,\n      this.output.context.currentTime + 2\n    );\n\n    // reset volume back\n    setTimeout(() => {\n      this.output.gain.gain.value = this.volume;\n      this.output.worklet.port.postMessage({ type: \"clearInterrupted\" });\n    }, 2000); // Adjust the duration as needed\n  };\n\n  private calculateVolume = (frequencyData: Uint8Array) => {\n    if (frequencyData.length === 0) {\n      return 0;\n    }\n\n    // TODO: Currently this averages all frequencies, but we should probably\n    // bias towards the frequencies that are more typical for human voice\n    let volume = 0;\n    for (let i = 0; i < frequencyData.length; i++) {\n      volume += frequencyData[i] / 255;\n    }\n    volume /= frequencyData.length;\n\n    return volume < 0 ? 0 : volume > 1 ? 1 : volume;\n  };\n\n  public setMicMuted(isMuted: boolean) {\n    // Use LiveKit track muting for WebRTC connections\n    if (this.connection instanceof WebRTCConnection) {\n      this.connection.setMicMuted(isMuted);\n    } else {\n      // Use input muting for WebSocket connections\n      this.input.setMuted(isMuted);\n    }\n  }\n\n  public getInputByteFrequencyData(): Uint8Array<ArrayBuffer> {\n    this.inputFrequencyData ??= new Uint8Array(\n      this.input.analyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.input.analyser.getByteFrequencyData(this.inputFrequencyData);\n    return this.inputFrequencyData;\n  }\n\n  public getOutputByteFrequencyData(): Uint8Array<ArrayBuffer> {\n    // Use WebRTC analyser if available\n    if (this.connection instanceof WebRTCConnection) {\n      const webrtcData = this.connection.getOutputByteFrequencyData();\n      if (webrtcData) {\n        return webrtcData as Uint8Array<ArrayBuffer>;\n      }\n      // Fallback to empty array if WebRTC analyser not ready\n      return new Uint8Array(1024) as Uint8Array<ArrayBuffer>;\n    }\n\n    this.outputFrequencyData ??= new Uint8Array(\n      this.output.analyser.frequencyBinCount\n    ) as Uint8Array<ArrayBuffer>;\n    this.output.analyser.getByteFrequencyData(this.outputFrequencyData);\n    return this.outputFrequencyData;\n  }\n\n  public getInputVolume() {\n    return this.calculateVolume(this.getInputByteFrequencyData());\n  }\n\n  public getOutputVolume() {\n    return this.calculateVolume(this.getOutputByteFrequencyData());\n  }\n\n  public async changeInputDevice({\n    sampleRate,\n    format,\n    preferHeadphonesForIosDevices,\n    inputDeviceId,\n  }: FormatConfig & InputConfig): Promise<Input> {\n    try {\n      // For WebSocket connections, try to change device on existing input first\n      if (this.connection instanceof WebSocketConnection) {\n        try {\n          await this.input.setInputDevice(inputDeviceId);\n          return this.input;\n        } catch (error) {\n          console.warn(\n            \"Failed to change device on existing input, recreating:\",\n            error\n          );\n          // Fall back to recreating the input\n        }\n      }\n\n      // Handle WebRTC connections differently\n      if (this.connection instanceof WebRTCConnection) {\n        await this.connection.setAudioInputDevice(inputDeviceId || \"\");\n      }\n\n      // Fallback: recreate the input\n      await this.input.close();\n\n      const newInput = await Input.create({\n        sampleRate: sampleRate ?? this.connection.inputFormat.sampleRate,\n        format: format ?? this.connection.inputFormat.format,\n        preferHeadphonesForIosDevices,\n        inputDeviceId,\n        workletPaths: this.options.workletPaths,\n        libsampleratePath: this.options.libsampleratePath,\n      });\n\n      this.input = newInput;\n      this.input.worklet.port.onmessage = this.onInputWorkletMessage;\n\n      return this.input;\n    } catch (error) {\n      console.error(\"Error changing input device\", error);\n      throw error;\n    }\n  }\n\n  public async changeOutputDevice({\n    sampleRate,\n    format,\n    outputDeviceId,\n  }: FormatConfig): Promise<Output> {\n    try {\n      // For WebSocket connections, try to change device on existing output first\n      if (this.connection instanceof WebSocketConnection) {\n        try {\n          await this.output.setOutputDevice(outputDeviceId);\n          return this.output;\n        } catch (error) {\n          console.warn(\n            \"Failed to change device on existing output, recreating:\",\n            error\n          );\n          // Fall back to recreating the output\n        }\n      }\n\n      // Handle WebRTC connections differently\n      if (this.connection instanceof WebRTCConnection) {\n        await this.connection.setAudioOutputDevice(outputDeviceId || \"\");\n      }\n\n      // Fallback: recreate the output\n      await this.output.close();\n\n      const newOutput = await Output.create({\n        sampleRate: sampleRate ?? this.connection.outputFormat.sampleRate,\n        format: format ?? this.connection.outputFormat.format,\n        outputDeviceId,\n        workletPaths: this.options.workletPaths,\n      });\n\n      this.output = newOutput;\n\n      return this.output;\n    } catch (error) {\n      console.error(\"Error changing output device\", error);\n      throw error;\n    }\n  }\n\n  public setVolume = ({ volume }: { volume: number }) => {\n    // clamp & coerce\n    const clampedVolume = Number.isFinite(volume)\n      ? Math.min(1, Math.max(0, volume))\n      : 1;\n    this.volume = clampedVolume;\n\n    if (this.connection instanceof WebRTCConnection) {\n      // For WebRTC connections, control volume via HTML audio elements\n      this.connection.setAudioVolume(clampedVolume);\n    } else {\n      // For WebSocket connections, control volume via gain node\n      this.output.gain.gain.value = clampedVolume;\n    }\n  };\n}\n","const HTTPS_API_ORIGIN = \"https://api.elevenlabs.io\";\n\nexport interface RatingFeedback {\n  rating: number;\n  comment?: string;\n}\n\ntype Feedback = RatingFeedback;\n\nexport function postOverallFeedback(\n  conversationId: string,\n  like: boolean,\n  origin?: string\n): Promise<Response>;\nexport function postOverallFeedback(\n  conversationId: string,\n  feedback: Feedback,\n  origin?: string\n): Promise<Response>;\nexport function postOverallFeedback(\n  conversationId: string,\n  likeOrFeedback: boolean | Feedback,\n  origin: string = HTTPS_API_ORIGIN\n): Promise<Response> {\n  const body: {\n    feedback?: \"like\" | \"dislike\";\n    rating?: number;\n    comment?: string;\n  } = {};\n\n  if (typeof likeOrFeedback === \"boolean\") {\n    body.feedback = likeOrFeedback ? \"like\" : \"dislike\";\n  } else {\n    body.rating = likeOrFeedback.rating;\n    body.comment = likeOrFeedback.comment;\n  }\n\n  return fetch(`${origin}/v1/convai/conversations/${conversationId}/feedback`, {\n    method: \"POST\",\n    body: JSON.stringify(body),\n    headers: {\n      \"Content-Type\": \"application/json\",\n    },\n  });\n}\n","import type {\n  InputAudioChunk,\n  SessionStartedMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n} from \"@elevenlabs/types\";\n\n// Re-export types for public API\nexport type {\n  SessionStartedMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n};\n\nexport type WebSocketMessage =\n  | SessionStartedMessage\n  | PartialTranscriptMessage\n  | CommittedTranscriptMessage\n  | CommittedTranscriptWithTimestampsMessage\n  | ScribeErrorMessage\n  | ScribeAuthErrorMessage\n  | ScribeQuotaExceededErrorMessage\n  | ScribeCommitThrottledErrorMessage\n  | ScribeTranscriberErrorMessage\n  | ScribeUnacceptedTermsErrorMessage\n  | ScribeRateLimitedErrorMessage\n  | ScribeInputErrorMessage\n  | ScribeQueueOverflowErrorMessage\n  | ScribeResourceExhaustedErrorMessage\n  | ScribeSessionTimeLimitExceededErrorMessage\n  | ScribeChunkSizeExceededErrorMessage\n  | ScribeInsufficientAudioActivityErrorMessage;\n\n/**\n * Simple EventEmitter implementation for browser compatibility.\n */\nclass EventEmitter {\n  private listeners: Map<string, Set<(...args: unknown[]) => void>> = new Map();\n\n  on(event: string, listener: (...args: unknown[]) => void): void {\n    if (!this.listeners.has(event)) {\n      this.listeners.set(event, new Set());\n    }\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.add(listener);\n    }\n  }\n\n  off(event: string, listener: (...args: unknown[]) => void): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.delete(listener);\n    }\n  }\n\n  emit(event: string, ...args: unknown[]): void {\n    const eventListeners = this.listeners.get(event);\n    if (eventListeners) {\n      eventListeners.forEach(listener => {\n        listener(...args);\n      });\n    }\n  }\n}\n\n/**\n * Events emitted by the RealtimeConnection.\n */\nexport enum RealtimeEvents {\n  /** Emitted when the session is successfully started */\n  SESSION_STARTED = \"session_started\",\n  /** Emitted when a partial (interim) transcript is available */\n  PARTIAL_TRANSCRIPT = \"partial_transcript\",\n  /** Emitted when a final transcript is available */\n  COMMITTED_TRANSCRIPT = \"committed_transcript\",\n  /** Emitted when a final transcript with timestamps is available */\n  COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS = \"committed_transcript_with_timestamps\",\n  /** Emitted when an authentication error occurs */\n  AUTH_ERROR = \"auth_error\",\n  /** Emitted when an error occurs (also emitted for all specific error types) */\n  ERROR = \"error\",\n  /** Emitted when the WebSocket connection is opened */\n  OPEN = \"open\",\n  /** Emitted when the WebSocket connection is closed */\n  CLOSE = \"close\",\n  /** Emitted when a quota exceeded error occurs */\n  QUOTA_EXCEEDED = \"quota_exceeded\",\n  /** Emitted when commit is throttled */\n  COMMIT_THROTTLED = \"commit_throttled\",\n  /** Emitted when a transcriber error occurs */\n  TRANSCRIBER_ERROR = \"transcriber_error\",\n  /** Emitted when terms have not been accepted */\n  UNACCEPTED_TERMS = \"unaccepted_terms\",\n  /** Emitted when rate limited */\n  RATE_LIMITED = \"rate_limited\",\n  /** Emitted when there's an input error */\n  INPUT_ERROR = \"input_error\",\n  /** Emitted when the queue overflows */\n  QUEUE_OVERFLOW = \"queue_overflow\",\n  /** Emitted when resources are exhausted */\n  RESOURCE_EXHAUSTED = \"resource_exhausted\",\n  /** Emitted when session time limit is exceeded */\n  SESSION_TIME_LIMIT_EXCEEDED = \"session_time_limit_exceeded\",\n  /** Emitted when chunk size is exceeded */\n  CHUNK_SIZE_EXCEEDED = \"chunk_size_exceeded\",\n  /** Emitted when there's insufficient audio activity */\n  INSUFFICIENT_AUDIO_ACTIVITY = \"insufficient_audio_activity\",\n}\n\n/**\n * Map of event types to their payload types.\n */\nexport interface RealtimeEventMap {\n  [RealtimeEvents.SESSION_STARTED]: SessionStartedMessage;\n  [RealtimeEvents.PARTIAL_TRANSCRIPT]: PartialTranscriptMessage;\n  [RealtimeEvents.COMMITTED_TRANSCRIPT]: CommittedTranscriptMessage;\n  [RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS]: CommittedTranscriptWithTimestampsMessage;\n  [RealtimeEvents.ERROR]: ScribeErrorMessage;\n  [RealtimeEvents.AUTH_ERROR]: ScribeAuthErrorMessage;\n  [RealtimeEvents.QUOTA_EXCEEDED]: ScribeQuotaExceededErrorMessage;\n  [RealtimeEvents.COMMIT_THROTTLED]: ScribeCommitThrottledErrorMessage;\n  [RealtimeEvents.TRANSCRIBER_ERROR]: ScribeTranscriberErrorMessage;\n  [RealtimeEvents.UNACCEPTED_TERMS]: ScribeUnacceptedTermsErrorMessage;\n  [RealtimeEvents.RATE_LIMITED]: ScribeRateLimitedErrorMessage;\n  [RealtimeEvents.INPUT_ERROR]: ScribeInputErrorMessage;\n  [RealtimeEvents.QUEUE_OVERFLOW]: ScribeQueueOverflowErrorMessage;\n  [RealtimeEvents.RESOURCE_EXHAUSTED]: ScribeResourceExhaustedErrorMessage;\n  [RealtimeEvents.SESSION_TIME_LIMIT_EXCEEDED]: ScribeSessionTimeLimitExceededErrorMessage;\n  [RealtimeEvents.CHUNK_SIZE_EXCEEDED]: ScribeChunkSizeExceededErrorMessage;\n  [RealtimeEvents.INSUFFICIENT_AUDIO_ACTIVITY]: ScribeInsufficientAudioActivityErrorMessage;\n  [RealtimeEvents.OPEN]: undefined;\n  [RealtimeEvents.CLOSE]: CloseEvent;\n}\n\n/**\n * Manages a real-time transcription WebSocket connection.\n *\n * @example\n * ```typescript\n * const connection = await Scribe.connect({\n *     token: \"...\",\n *     modelId: \"scribe_v2_realtime\",\n *     audioFormat: AudioFormat.PCM_16000,\n *     sampleRate: 16000,\n * });\n *\n * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {\n *     console.log(\"Session started\");\n * });\n *\n * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {\n *     console.log(\"Partial:\", data.transcript);\n * });\n *\n * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n *     console.log(\"Final:\", data.transcript);\n *     connection.close();\n * });\n *\n * // Send audio data\n * connection.send({ audioBase64: base64String });\n *\n * // Commit and close\n * connection.commit();\n * ```\n */\nexport class RealtimeConnection {\n  private websocket: WebSocket | null = null;\n  private eventEmitter: EventEmitter = new EventEmitter();\n  private currentSampleRate: number = 16000;\n  public _audioCleanup?: () => void;\n\n  constructor(sampleRate: number) {\n    this.currentSampleRate = sampleRate;\n  }\n\n  /**\n   * @internal\n   * Used internally by ScribeRealtime to attach the WebSocket after connection is created.\n   */\n  public setWebSocket(websocket: WebSocket): void {\n    this.websocket = websocket;\n\n    // If WebSocket is already open, emit OPEN event immediately\n    if (this.websocket.readyState === WebSocket.OPEN) {\n      this.eventEmitter.emit(RealtimeEvents.OPEN);\n    } else {\n      // Otherwise, wait for the open event\n      this.websocket.addEventListener(\"open\", () => {\n        this.eventEmitter.emit(RealtimeEvents.OPEN);\n      });\n    }\n\n    this.websocket.addEventListener(\"message\", (event: MessageEvent) => {\n      try {\n        const data = JSON.parse(event.data) as WebSocketMessage;\n\n        switch (data.message_type) {\n          case \"session_started\":\n            this.eventEmitter.emit(RealtimeEvents.SESSION_STARTED, data);\n            break;\n          case \"partial_transcript\":\n            this.eventEmitter.emit(RealtimeEvents.PARTIAL_TRANSCRIPT, data);\n            break;\n          case \"committed_transcript\":\n            this.eventEmitter.emit(RealtimeEvents.COMMITTED_TRANSCRIPT, data);\n            break;\n          case \"committed_transcript_with_timestamps\":\n            this.eventEmitter.emit(\n              RealtimeEvents.COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS,\n              data\n            );\n            break;\n          // Error cases - emit both specific event and generic ERROR\n          case \"auth_error\":\n            this.eventEmitter.emit(RealtimeEvents.AUTH_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"quota_exceeded\":\n            this.eventEmitter.emit(RealtimeEvents.QUOTA_EXCEEDED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"commit_throttled\":\n            this.eventEmitter.emit(RealtimeEvents.COMMIT_THROTTLED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"transcriber_error\":\n            this.eventEmitter.emit(RealtimeEvents.TRANSCRIBER_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"unaccepted_terms\":\n            this.eventEmitter.emit(RealtimeEvents.UNACCEPTED_TERMS, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"rate_limited\":\n            this.eventEmitter.emit(RealtimeEvents.RATE_LIMITED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"input_error\":\n            this.eventEmitter.emit(RealtimeEvents.INPUT_ERROR, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"queue_overflow\":\n            this.eventEmitter.emit(RealtimeEvents.QUEUE_OVERFLOW, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"resource_exhausted\":\n            this.eventEmitter.emit(RealtimeEvents.RESOURCE_EXHAUSTED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"session_time_limit_exceeded\":\n            this.eventEmitter.emit(\n              RealtimeEvents.SESSION_TIME_LIMIT_EXCEEDED,\n              data\n            );\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"chunk_size_exceeded\":\n            this.eventEmitter.emit(RealtimeEvents.CHUNK_SIZE_EXCEEDED, data);\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"insufficient_audio_activity\":\n            this.eventEmitter.emit(\n              RealtimeEvents.INSUFFICIENT_AUDIO_ACTIVITY,\n              data\n            );\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          case \"error\":\n            this.eventEmitter.emit(RealtimeEvents.ERROR, data);\n            break;\n          default:\n            console.warn(\"Unknown message type:\", data);\n        }\n      } catch (error) {\n        console.error(\"Failed to parse WebSocket message:\", error, event.data);\n        this.eventEmitter.emit(\n          RealtimeEvents.ERROR,\n          new Error(`Failed to parse message: ${error}`)\n        );\n      }\n    });\n\n    this.websocket.addEventListener(\"error\", (error: Event) => {\n      console.error(\"WebSocket error:\", error);\n      this.eventEmitter.emit(RealtimeEvents.ERROR, error);\n    });\n\n    this.websocket.addEventListener(\"close\", (event: CloseEvent) => {\n      console.log(\n        `WebSocket closed: code=${event.code}, reason=\"${event.reason}\", wasClean=${event.wasClean}`\n      );\n\n      // Emit error if close was not clean or had an error code\n      if (!event.wasClean || (event.code !== 1000 && event.code !== 1005)) {\n        const errorMessage = `WebSocket closed unexpectedly: ${event.code} - ${event.reason || \"No reason provided\"}`;\n        console.error(errorMessage);\n        this.eventEmitter.emit(RealtimeEvents.ERROR, new Error(errorMessage));\n      }\n\n      this.eventEmitter.emit(RealtimeEvents.CLOSE, event);\n    });\n  }\n\n  /**\n   * Attaches an event listener for the specified event.\n   *\n   * @param event - The event to listen for (use RealtimeEvents enum)\n   * @param listener - The callback function to execute when the event fires\n   *\n   * @example\n   * ```typescript\n   * connection.on(RealtimeEvents.SESSION_STARTED, (data) => {\n   *     console.log(\"Session started\", data.session_id);\n   * });\n   *\n   * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, (data) => {\n   *     console.log(\"Partial:\", data.text);\n   * });\n   *\n   * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n   *     console.log(\"Final:\", data.text);\n   * });\n   * ```\n   */\n  public on<E extends RealtimeEvents>(\n    event: E,\n    listener: RealtimeEventMap[E] extends undefined\n      ? () => void\n      : (data: RealtimeEventMap[E]) => void\n  ): void {\n    this.eventEmitter.on(event, listener as (...args: unknown[]) => void);\n  }\n\n  /**\n   * Removes an event listener for the specified event.\n   *\n   * @param event - The event to stop listening for\n   * @param listener - The callback function to remove\n   *\n   * @example\n   * ```typescript\n   * const handler = (data: PartialTranscriptMessage) => console.log(data.text);\n   * connection.on(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);\n   *\n   * // Later, remove the listener\n   * connection.off(RealtimeEvents.PARTIAL_TRANSCRIPT, handler);\n   * ```\n   */\n  public off<E extends RealtimeEvents>(\n    event: E,\n    listener: RealtimeEventMap[E] extends undefined\n      ? () => void\n      : (data: RealtimeEventMap[E]) => void\n  ): void {\n    this.eventEmitter.off(event, listener as (...args: unknown[]) => void);\n  }\n\n  /**\n   * Sends audio data to the transcription service.\n   *\n   * @param data - Audio data configuration\n   * @param data.audioBase64 - Base64-encoded audio data\n   * @param data.commit - Whether to commit the transcription after this chunk. You likely want to use connection.commit() instead (default: false)\n   * @param data.sampleRate - Sample rate of the audio (default: configured sample rate)\n   * @param data.previousText - Send context to the model via base64 encoded audio or text from a previous transcription. Can only be sent alongside the first audio chunk. If sent in a subsequent chunk, an error will be returned.\n   *\n   * @throws {Error} If the WebSocket connection is not open\n   *\n   * @example\n   * ```typescript\n   * // Send audio chunk without committing\n   * connection.send({\n   *     audioBase64: base64EncodedAudio,\n   * });\n   *\n   * // Send audio chunk with custom sample rate and previous text\n   * connection.send({\n   *     audioBase64: base64EncodedAudio,\n   *     sampleRate: 16000,\n   *     previousText: \"Previous transcription text\",\n   * });\n   * ```\n   */\n  public send(data: {\n    audioBase64: string;\n    commit?: boolean;\n    sampleRate?: number;\n    previousText?: string;\n  }): void {\n    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {\n      throw new Error(\"WebSocket is not connected\");\n    }\n\n    const message: InputAudioChunk = {\n      message_type: \"input_audio_chunk\",\n      audio_base_64: data.audioBase64,\n      commit: data.commit ?? false,\n      sample_rate: data.sampleRate ?? this.currentSampleRate,\n      previous_text: data.previousText,\n    };\n\n    this.websocket.send(JSON.stringify(message));\n  }\n\n  /**\n   * Commits the transcription, signaling that a segment of audio has been sent. This clears the buffer and triggers a COMMITTED_TRANSCRIPT event. Context from previous segments is kept.\n   * Committing a segment triggers a COMMITTED_TRANSCRIPT event.\n   *\n   * @throws {Error} If the WebSocket connection is not open\n   *\n   * @remarks\n   * Only needed when using CommitStrategy.MANUAL.\n   * When using CommitStrategy.VAD, commits are handled automatically by the server.\n   *\n   * @example\n   * ```typescript\n   * // Send all audio chunks\n   * for (const chunk of audioChunks) {\n   *     connection.send({ audioBase64: chunk });\n   * }\n   *\n   * // Finalize the transcription\n   * connection.commit();\n   * ```\n   */\n  public commit(): void {\n    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {\n      throw new Error(\"WebSocket is not connected\");\n    }\n\n    const message: InputAudioChunk = {\n      message_type: \"input_audio_chunk\",\n      audio_base_64: \"\",\n      commit: true,\n      sample_rate: this.currentSampleRate,\n    };\n\n    this.websocket.send(JSON.stringify(message));\n  }\n\n  /**\n   * Closes the WebSocket connection and cleans up resources.\n   * This will terminate any ongoing transcription and stop microphone streaming if active.\n   *\n   * @remarks\n   * After calling close(), this connection cannot be reused.\n   * Create a new connection if you need to start transcribing again.\n   *\n   * @example\n   * ```typescript\n   * connection.on(RealtimeEvents.COMMITTED_TRANSCRIPT, (data) => {\n   *     console.log(\"Segment committed:\", data.transcript);\n   *     connection.close();\n   * });\n   * ```\n   */\n  public close(): void {\n    // Cleanup audio resources (microphone stream, audio context)\n    if (this._audioCleanup) {\n      this._audioCleanup();\n    }\n\n    // Close WebSocket connection\n    if (this.websocket) {\n      this.websocket.close();\n    }\n  }\n}\n","// AUTO-GENERATED BY packages/client/scripts/generateWorklets.js\nimport { createWorkletModuleLoader } from \"./createWorkletModuleLoader\";\n\nexport const loadScribeAudioProcessor = createWorkletModuleLoader(\n  \"scribeAudioProcessor\",\n  // language=JavaScript\n  `/*\n * Scribe Audio Processor for converting microphone audio to PCM16 format\n * USED BY @elevenlabs/client\n */\n\nclass ScribeAudioProcessor extends AudioWorkletProcessor {\n  constructor() {\n    super();\n    this.buffer = [];\n    this.bufferSize = 4096; // Buffer size for optimal chunk transmission\n  }\n\n  process(inputs) {\n    const input = inputs[0];\n    if (input.length > 0) {\n      const channelData = input[0]; // Get first channel (mono)\n\n      // Add incoming audio to buffer\n      this.buffer.push(...channelData);\n\n      // When buffer reaches threshold, convert and send\n      if (this.buffer.length >= this.bufferSize) {\n        const float32Array = new Float32Array(this.buffer);\n        const int16Array = new Int16Array(float32Array.length);\n\n        // Convert Float32 [-1, 1] to Int16 [-32768, 32767]\n        for (let i = 0; i < float32Array.length; i++) {\n          // Clamp the value to prevent overflow\n          const sample = Math.max(-1, Math.min(1, float32Array[i]));\n          // Scale to PCM16 range\n          int16Array[i] = sample < 0 ? sample * 32768 : sample * 32767;\n        }\n\n        // Send to main thread as transferable ArrayBuffer\n        this.port.postMessage(\n          {\n            audioData: int16Array.buffer\n          },\n          [int16Array.buffer]\n        );\n\n        // Clear buffer\n        this.buffer = [];\n      }\n    }\n\n    return true; // Continue processing\n  }\n}\n\nregisterProcessor(\"scribeAudioProcessor\", ScribeAudioProcessor);\n\n`\n);\n","import { RealtimeConnection } from \"./connection\";\nimport { loadScribeAudioProcessor } from \"../utils/scribeAudioProcessor.generated\";\n\nexport enum AudioFormat {\n  PCM_8000 = \"pcm_8000\",\n  PCM_16000 = \"pcm_16000\",\n  PCM_22050 = \"pcm_22050\",\n  PCM_24000 = \"pcm_24000\",\n  PCM_44100 = \"pcm_44100\",\n  PCM_48000 = \"pcm_48000\",\n  ULAW_8000 = \"ulaw_8000\",\n}\n\nexport enum CommitStrategy {\n  MANUAL = \"manual\",\n  VAD = \"vad\",\n}\n\ninterface BaseOptions {\n  /**\n   * Token to use for the WebSocket connection. Obtained from the ElevenLabs API.\n   */\n  token: string;\n  /**\n   * Strategy for committing transcriptions.\n   * @default CommitStrategy.MANUAL\n   */\n  commitStrategy?: CommitStrategy;\n  /**\n   * Silence threshold in seconds for VAD (Voice Activity Detection).\n   * Must be a positive number between 0.3 and 3.0\n   */\n  vadSilenceThresholdSecs?: number;\n  /**\n   * Threshold for voice activity detection.\n   * Must be between 0.1 and 0.9.\n   */\n  vadThreshold?: number;\n  /**\n   * Minimum speech duration in milliseconds.\n   * Must be a positive integer between 50 and 2000.\n   */\n  minSpeechDurationMs?: number;\n  /**\n   * Minimum silence duration in milliseconds.\n   * Must be a positive integer between 50 and 2000.\n   */\n  minSilenceDurationMs?: number;\n  /**\n   * Model ID to use for transcription.\n   * Must be a valid model ID.\n   */\n  modelId: string;\n  /**\n   * An ISO-639-1 or ISO-639-3 language_code corresponding to the language of the audio file.\n   * Can sometimes improve transcription performance if known beforehand.\n   */\n  languageCode?: string;\n  /**\n   * Base URI to use for the WebSocket connection.\n   * If not provided, the default URI will be used.\n   */\n  baseUri?: string;\n  /**\n   * Whether to receive a committed_transcript_with_timestamps event which includes word-level timestamps.\n   * @default false\n   */\n  includeTimestamps?: boolean;\n}\n\nexport interface AudioOptions extends BaseOptions {\n  audioFormat: AudioFormat;\n  sampleRate: number;\n  microphone?: never;\n}\n\n/**\n * Options for automatic microphone streaming in the browser.\n */\nexport interface MicrophoneOptions extends BaseOptions {\n  microphone?: {\n    deviceId?: string;\n    echoCancellation?: boolean;\n    noiseSuppression?: boolean;\n    autoGainControl?: boolean;\n    channelCount?: number;\n  };\n  audioFormat?: never;\n  sampleRate?: never;\n}\n\n/**\n * Real-time speech-to-text transcription client for browser environments.\n * Supports microphone streaming and manual audio chunk transmission.\n */\n\n// biome-ignore lint/complexity/noStaticOnlyClass: This class is static only because it is a singleton\nexport class ScribeRealtime {\n  private static readonly DEFAULT_BASE_URI = \"wss://api.elevenlabs.io\";\n\n  private static getWebSocketUri(\n    baseUri: string = ScribeRealtime.DEFAULT_BASE_URI\n  ): string {\n    return `${baseUri}/v1/speech-to-text/realtime`;\n  }\n\n  private static buildWebSocketUri(\n    options: AudioOptions | MicrophoneOptions\n  ): string {\n    const baseUri = ScribeRealtime.getWebSocketUri(options.baseUri);\n    const params = new URLSearchParams();\n\n    // Model ID is required, so no check required\n    params.append(\"model_id\", options.modelId);\n\n    params.append(\"token\", options.token);\n\n    // Add optional parameters if provided, with validation\n    if (options.commitStrategy !== undefined) {\n      params.append(\"commit_strategy\", options.commitStrategy);\n    }\n    if (options.vadSilenceThresholdSecs !== undefined) {\n      if (\n        options.vadSilenceThresholdSecs <= 0.3 ||\n        options.vadSilenceThresholdSecs > 3.0\n      ) {\n        throw new Error(\"vadSilenceThresholdSecs must be between 0.3 and 3.0\");\n      }\n      params.append(\n        \"vad_silence_threshold_secs\",\n        options.vadSilenceThresholdSecs.toString()\n      );\n    }\n    if (options.vadThreshold !== undefined) {\n      if (options.vadThreshold < 0.1 || options.vadThreshold > 0.9) {\n        throw new Error(\"vadThreshold must be between 0.1 and 0.9\");\n      }\n      params.append(\"vad_threshold\", options.vadThreshold.toString());\n    }\n    if (options.minSpeechDurationMs !== undefined) {\n      if (\n        options.minSpeechDurationMs <= 50 ||\n        options.minSpeechDurationMs > 2000\n      ) {\n        throw new Error(\"minSpeechDurationMs must be between 50 and 2000\");\n      }\n      params.append(\n        \"min_speech_duration_ms\",\n        options.minSpeechDurationMs.toString()\n      );\n    }\n    if (options.minSilenceDurationMs !== undefined) {\n      if (\n        options.minSilenceDurationMs <= 50 ||\n        options.minSilenceDurationMs > 2000\n      ) {\n        throw new Error(\"minSilenceDurationMs must be between 50 and 2000\");\n      }\n      params.append(\n        \"min_silence_duration_ms\",\n        options.minSilenceDurationMs.toString()\n      );\n    }\n    if (options.languageCode !== undefined) {\n      params.append(\"language_code\", options.languageCode);\n    }\n    if (options.includeTimestamps !== undefined) {\n      params.append(\n        \"include_timestamps\",\n        options.includeTimestamps ? \"true\" : \"false\"\n      );\n    }\n\n    const queryString = params.toString();\n    return queryString ? `${baseUri}?${queryString}` : baseUri;\n  }\n\n  /**\n   * Establishes a WebSocket connection for real-time speech-to-text transcription.\n   *\n   * @param options - Configuration options for the connection\n   * @returns A RealtimeConnection instance\n   *\n   * @example\n   * ```typescript\n   * // Manual audio streaming\n   * const connection = Scribe.connect({\n   *     token: \"...\",\n   *     modelId: \"scribe_v2_realtime\",\n   *     audioFormat: AudioFormat.PCM_16000,\n   *     sampleRate: 16000,\n   * });\n   *\n   * // Automatic microphone streaming\n   * const connection = Scribe.connect({\n   *     token: \"...\",\n   *     modelId: \"scribe_v2_realtime\",\n   *     microphone: {\n   *         echoCancellation: true,\n   *         noiseSuppression: true\n   *     }\n   * });\n   * ```\n   */\n  public static connect(\n    options: AudioOptions | MicrophoneOptions\n  ): RealtimeConnection {\n    if (!options.modelId) {\n      throw new Error(\"modelId is required\");\n    }\n\n    // Create connection object first so users can attach event listeners before messages arrive\n    const sampleRate =\n      \"microphone\" in options && options.microphone\n        ? 16000\n        : (options as AudioOptions).sampleRate;\n    const connection = new RealtimeConnection(sampleRate);\n\n    // Build WebSocket URI with query parameters\n    const uri = ScribeRealtime.buildWebSocketUri(options);\n\n    const websocket = new WebSocket(uri);\n\n    // If microphone mode, set up streaming handler\n    if (\"microphone\" in options && options.microphone) {\n      websocket.addEventListener(\"open\", () => {\n        ScribeRealtime.streamFromMicrophone(\n          options as MicrophoneOptions,\n          connection\n        );\n      });\n    }\n\n    connection.setWebSocket(websocket);\n\n    return connection;\n  }\n\n  private static async streamFromMicrophone(\n    options: MicrophoneOptions,\n    connection: RealtimeConnection\n  ): Promise<void> {\n    try {\n      // Get microphone access\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: {\n          deviceId: options.microphone?.deviceId,\n          echoCancellation: options.microphone?.echoCancellation ?? true,\n          noiseSuppression: options.microphone?.noiseSuppression ?? true,\n          autoGainControl: options.microphone?.autoGainControl ?? true,\n          channelCount: options.microphone?.channelCount ?? 1,\n          sampleRate: { ideal: 16000 },\n        },\n      });\n\n      // Create audio context at 16kHz (Scribe's default)\n      const audioContext = new AudioContext({ sampleRate: 16000 });\n\n      // Load scribe worklet\n      await loadScribeAudioProcessor(audioContext.audioWorklet);\n\n      // Set up audio pipeline\n      const source = audioContext.createMediaStreamSource(stream);\n      const workletNode = new AudioWorkletNode(\n        audioContext,\n        \"scribeAudioProcessor\"\n      );\n\n      // Handle audio data from worklet\n      workletNode.port.onmessage = event => {\n        const { audioData } = event.data;\n        // Convert ArrayBuffer to base64\n        const bytes = new Uint8Array(audioData);\n        let binary = \"\";\n        for (let i = 0; i < bytes.length; i++) {\n          binary += String.fromCharCode(bytes[i]);\n        }\n        const base64Audio = btoa(binary);\n\n        connection.send({ audioBase64: base64Audio });\n      };\n\n      // Connect audio pipeline\n      source.connect(workletNode);\n\n      // Resume audio context if needed\n      if (audioContext.state === \"suspended\") {\n        await audioContext.resume();\n      }\n\n      // Store cleanup function\n      connection._audioCleanup = () => {\n        stream.getTracks().forEach(track => {\n          track.stop();\n        });\n        source.disconnect();\n        workletNode.disconnect();\n        audioContext.close();\n      };\n    } catch (error) {\n      console.error(\"Failed to start microphone streaming:\", error);\n      throw error;\n    }\n  }\n}\n","import { BaseConversation, type PartialOptions } from \"./BaseConversation\";\nimport { TextConversation } from \"./TextConversation\";\nimport { VoiceConversation } from \"./VoiceConversation\";\n\nexport type {\n  Mode,\n  Role,\n  Options,\n  PartialOptions,\n  ClientToolsConfig,\n  Callbacks,\n  Status,\n  AudioWorkletConfig,\n} from \"./BaseConversation\";\nexport type { InputConfig } from \"./utils/input\";\nexport type { OutputConfig } from \"./utils/output\";\nexport { Input } from \"./utils/input\";\nexport { Output } from \"./utils/output\";\nexport type { IncomingSocketEvent, VadScoreEvent } from \"./utils/events\";\nexport type {\n  SessionConfig,\n  BaseSessionConfig,\n  DisconnectionDetails,\n  Language,\n  ConnectionType,\n  FormatConfig,\n} from \"./utils/BaseConnection\";\nexport { createConnection } from \"./utils/ConnectionFactory\";\nexport { WebSocketConnection } from \"./utils/WebSocketConnection\";\nexport { WebRTCConnection } from \"./utils/WebRTCConnection\";\nexport { postOverallFeedback } from \"./utils/postOverallFeedback\";\nexport { VoiceConversation } from \"./VoiceConversation\";\nexport { TextConversation } from \"./TextConversation\";\n\n// Scribe exports\nexport {\n  Scribe,\n  AudioFormat,\n  CommitStrategy,\n  RealtimeEvents,\n  RealtimeConnection,\n} from \"./scribe\";\nexport type {\n  AudioOptions,\n  MicrophoneOptions,\n  WebSocketMessage,\n  PartialTranscriptMessage,\n  CommittedTranscriptMessage,\n  CommittedTranscriptWithTimestampsMessage,\n  ScribeErrorMessage,\n  ScribeAuthErrorMessage,\n  ScribeQuotaExceededErrorMessage,\n  ScribeCommitThrottledErrorMessage,\n  ScribeTranscriberErrorMessage,\n  ScribeUnacceptedTermsErrorMessage,\n  ScribeRateLimitedErrorMessage,\n  ScribeInputErrorMessage,\n  ScribeQueueOverflowErrorMessage,\n  ScribeResourceExhaustedErrorMessage,\n  ScribeSessionTimeLimitExceededErrorMessage,\n  ScribeChunkSizeExceededErrorMessage,\n  ScribeInsufficientAudioActivityErrorMessage,\n} from \"./scribe\";\n\nexport class Conversation extends BaseConversation {\n  public static startSession(options: PartialOptions): Promise<Conversation> {\n    return options.textOnly\n      ? TextConversation.startSession(options)\n      : VoiceConversation.startSession(options);\n  }\n}\n"],"names":["EMPTY_FREQUENCY_DATA","Uint8Array","BaseConversation","getFullOptions","partialOptions","_extends","clientTools","onConnect","onDebug","onDisconnect","onError","onMessage","onAudio","onModeChange","onStatusChange","onCanSendFeedbackChange","onInterruption","constructor","options","connection","_this","lastInterruptTimestamp","this","mode","status","volume","currentEventId","lastFeedbackEventId","canSendFeedback","endSessionWithDetails","async","details","updateStatus","handleEndSession","parsedEvent","type","handleInterruption","handleAgentResponse","handleUserTranscript","handleTentativeAgentResponse","handleClientToolCall","error","Error","message","String","clientToolName","client_tool_call","tool_name","toolCallId","tool_call_id","handleAudio","handleVadScore","sendMessage","event_id","ping_event","handleMCPToolCall","handleMCPConnectionStatus","handleAgentToolRequest","handleAgentToolResponse","handleConversationMetadata","handleAsrInitiationMetadata","handleAgentChatResponsePart","handleErrorEvent","setVolume","conversationId","updateMode","endSession","reason","close","updateCanSendFeedback","event","interruption_event","source","role","agent_response_event","agent_response","user_transcription_event","user_transcript","response","tentative_agent_response_internal_event","tentative_agent_response","onVadScore","vadScore","vad_score_event","vad_score","Object","prototype","hasOwnProperty","call","_await$this$options$c","result","parameters","formattedResult","JSON","stringify","is_error","e","onUnhandledClientToolCall","onMCPToolCall","mcp_tool_call","onMCPConnectionStatus","mcp_connection_status","onAgentToolRequest","agent_tool_request","agent_tool_response","context","CloseEvent","onAgentToolResponse","onConversationMetadata","conversation_initiation_metadata_event","onAsrInitiationMetadata","asr_initiation_metadata_event","onAgentChatResponsePart","text_response_part","errorType","error_event","error_type","code","debugMessage","debug_message","Event","console","getId","isOpen","setMicMuted","isMuted","getInputByteFrequencyData","getOutputByteFrequencyData","getInputVolume","getOutputVolume","sendFeedback","like","score","warn","sendContextualUpdate","text","sendUserMessage","sendUserActivity","sendMCPToolApprovalResult","isApproved","is_approved","BaseConnection","config","queue","disconnectionDetails","onDisconnectCallback","onMessageCallback","onModeChangeCallback","debug","info","callback","length","queueMicrotask","forEach","_this$onModeChangeCal","disconnect","_this$onDisconnectCal","handleMessage","push","parseFormat","format","formatPart","sampleRatePart","split","includes","sampleRate","Number","parseInt","isNaN","PACKAGE_VERSION","isValidSocketEvent","CONVERSATION_INITIATION_CLIENT_DATA_TYPE","constructOverrides","_config$overrides","overridesEvent","_config$overrides$age","_config$overrides$age2","_config$overrides$age3","_config$overrides$tts","_config$overrides$con","overrides","conversation_config_override","agent","prompt","first_message","firstMessage","language","tts","voice_id","voiceId","conversation","text_only","textOnly","customLlmExtraBody","custom_llm_extra_body","dynamicVariables","dynamic_variables","userId","user_id","client","source_info","version","WebSocketConnection","socket","inputFormat","outputFormat","super","addEventListener","setTimeout","parse","data","create","_config$origin","_config$overrides2","origin","url","signedUrl","separator","agentId","protocols","authorization","WebSocket","conversationConfig","Promise","resolve","reject","_socket","send","once","conversation_id","agent_output_audio_format","user_input_audio_format","_socket2","arrayBufferToBase64","b","buffer","window","btoa","fromCharCode","base64ToArrayBuffer","base64","binaryString","atob","len","bytes","i","charCodeAt","URLCache","Map","createWorkletModuleLoader","name","sourceCode","worklet","path","cachedUrl","get","addModule","set","blob","Blob","blobURL","URL","createObjectURL","_unused","revokeObjectURL","moduleURL","loadRawAudioProcessor","WebRTCConnection","room","isConnected","audioEventId","audioCaptureContext","audioElements","outputDeviceId","outputAnalyser","outputFrequencyData","setupRoomEventListeners","conversationToken","replace","fetch","ok","statusText","json","token","msg","Room","Date","now","livekitUrl","_room$name$match","connect","onConnected","off","RoomEvent","Connected","on","match","localParticipant","setMicrophoneEnabled","Disconnected","toString","ConnectionStateChanged","state","ConnectionState","DataReceived","payload","_participant","TextDecoder","decode","TrackSubscribed","track","_publication","participant","kind","Track","Kind","Audio","identity","remoteAudioTrack","audioElement","attach","autoplay","controls","setSinkId","style","display","document","body","appendChild","setupAudioCapture","ActiveSpeakersChanged","speakers","startsWith","ParticipantDisconnected","_participant$identity","audioTrackPublications","publication","stop","catch","element","parentNode","removeChild","TextEncoder","encode","publishData","reliable","getRoom","micTrackPublication","getTrackPublication","Source","Microphone","mute","unmute","_error","audioContext","AudioContext","createAnalyser","fftSize","smoothingTimeConstant","mediaStream","MediaStream","mediaStreamTrack","createMediaStreamSource","audioWorklet","AudioWorkletNode","port","postMessage","onmessage","audioData","maxVolume","base64Audio","eventId","audio_event","audio_base_64","setAudioVolume","setAudioOutputDevice","deviceId","HTMLAudioElement","promises","map","all","setAudioInputDevice","currentMicTrackPublication","unpublishTrack","audioConstraints","exact","echoCancellation","noiseSuppression","autoGainControl","channelCount","ideal","audioTrack","createLocalAudioTrack","publishTrack","recoveryError","_this$outputFrequency","frequencyBinCount","getByteFrequencyData","createConnection","connectionType","determineConnectionType","isIosDevice","navigator","platform","userAgent","applyDelay","delayConfig","default","android","delay","_delayConfig$android","test","_delayConfig$ios","ios","TextConversation","startSession","fullOptions","connectionDelay","_connection","defaultConstraints","Input","preferHeadphonesForIosDevices","inputDeviceId","workletPaths","libsampleratePath","inputStream","idealDevice","mediaDevices","enumerateDevices","find","d","keyword","label","toLowerCase","getDeviceIdConstraint","supportsSampleRateConstraint","getSupportedConstraints","analyser","libsamplerateUrl","constraints","voiceIsolation","getUserMedia","audio","resume","_inputStream","_context","getTracks","mediaStreamSource","setMuted","setInputDevice","newInputStream","loadAudioConcatProcessor","Output","gain","createGain","src","load","destination","createMediaStreamDestination","srcObject","stream","_audioElement","_audioElement2","pause","setOutputDevice","VoiceConversation","_options$useWakeLock","input","output","preliminaryInputStream","wakeLock","useWakeLock","request","_e","_preliminaryInputStre","_preliminaryInputStre2","_input","_output","_wakeLock","release","inputFrequencyData","onInputWorkletMessage","user_audio_chunk","onOutputWorkletMessage","finished","addAudioBase64Chunk","chunk","cancelScheduledValues","currentTime","value","fadeOutAudio","exponentialRampToValueAtTime","calculateVolume","frequencyData","clampedVolume","isFinite","Math","min","max","_this$wakeLock","_this$options$onAudio","_this$options","changeInputDevice","newInput","changeOutputDevice","newOutput","postOverallFeedback","likeOrFeedback","feedback","rating","comment","method","headers","EventEmitter","listeners","listener","has","Set","eventListeners","add","delete","emit","args","RealtimeEvents","RealtimeConnection","websocket","eventEmitter","currentSampleRate","_audioCleanup","setWebSocket","readyState","OPEN","message_type","SESSION_STARTED","PARTIAL_TRANSCRIPT","COMMITTED_TRANSCRIPT","COMMITTED_TRANSCRIPT_WITH_TIMESTAMPS","AUTH_ERROR","ERROR","QUOTA_EXCEEDED","COMMIT_THROTTLED","TRANSCRIBER_ERROR","UNACCEPTED_TERMS","RATE_LIMITED","INPUT_ERROR","QUEUE_OVERFLOW","RESOURCE_EXHAUSTED","SESSION_TIME_LIMIT_EXCEEDED","CHUNK_SIZE_EXCEEDED","INSUFFICIENT_AUDIO_ACTIVITY","log","wasClean","errorMessage","CLOSE","_data$commit","_data$sampleRate","audioBase64","commit","sample_rate","previous_text","previousText","loadScribeAudioProcessor","AudioFormat","CommitStrategy","ScribeRealtime","getWebSocketUri","baseUri","DEFAULT_BASE_URI","buildWebSocketUri","params","URLSearchParams","append","modelId","undefined","commitStrategy","vadSilenceThresholdSecs","vadThreshold","minSpeechDurationMs","minSilenceDurationMs","languageCode","includeTimestamps","queryString","microphone","uri","streamFromMicrophone","_options$microphone","_options$microphone$e","_options$microphone2","_options$microphone$n","_options$microphone3","_options$microphone$a","_options$microphone4","_options$microphone$c","_options$microphone5","workletNode","binary","Conversation"],"mappings":"wUA+DA,MAAMA,EAAuB,IAAIC,WAAW,SAE/BC,EASD,qBAAOC,CAAeC,GAC9B,OAAAC,EACEC,CAAAA,YAAa,CAAA,EACbC,UAAWA,OACXC,QAASA,OACTC,aAAcA,OACdC,QAASA,OACTC,UAAWA,OACXC,QAASA,OACTC,aAAcA,OACdC,eAAgBA,OAChBC,wBAAyBA,OACzBC,eAAgBA,QACbZ,EAEP,CAEAa,WAAAA,CACqBC,EACAC,GAA0B,IAAAC,EAD1BF,KAAAA,KAAAA,aACAC,EAAAA,KAAAA,gBA3BXE,EAAAA,KAAAA,uBAAyB,EAACC,KAC1BC,KAAa,YAAWD,KACxBE,OAAiB,aACjBC,KAAAA,OAAS,OACTC,eAAiB,EAACJ,KAClBK,oBAAsB,EACtBC,KAAAA,iBAAkB,EAoCpBC,KAAAA,sBAAwBC,eAAOC,GACjB,cAAhBX,EAAKI,QAA0C,eAAhBJ,EAAKI,SACxCJ,EAAKY,aAAa,uBACZZ,EAAKa,mBACXb,EAAKY,aAAa,gBACdZ,EAAKF,QAAQT,cACfW,EAAKF,QAAQT,aAAasB,GAE9B,EA6NQpB,KAAAA,UAAYmB,eAAOI,GACzB,OAAQA,EAAYC,MAClB,IAAK,eAEH,YADAf,EAAKgB,mBAAmBF,GAG1B,IAAK,iBAEH,YADAd,EAAKiB,oBAAoBH,GAG3B,IAAK,kBAEH,YADAd,EAAKkB,qBAAqBJ,GAG5B,IAAK,oCAEH,YADAd,EAAKmB,6BAA6BL,GAGpC,IAAK,mBACH,UACQd,EAAKoB,qBAAqBN,EAClC,CAAE,MAAOO,GACPrB,EAAKV,QACH,kDAAkD+B,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,KAClG,CACEI,eAAgBX,EAAYY,iBAAiBC,UAC7CC,WAAYd,EAAYY,iBAAiBG,cAG/C,CACA,OAEF,IAAK,QAEH,YADA7B,EAAK8B,YAAYhB,GAInB,IAAK,YAEH,YADAd,EAAK+B,eAAejB,GAItB,IAAK,OAOH,YANAd,EAAKD,WAAWiC,YAAY,CAC1BjB,KAAM,OACNkB,SAAUnB,EAAYoB,WAAWD,WAOrC,IAAK,gBAEH,YADAjC,EAAKmC,kBAAkBrB,GAIzB,IAAK,wBAEH,YADAd,EAAKoC,0BAA0BtB,GAIjC,IAAK,qBAEH,YADAd,EAAKqC,uBAAuBvB,GAI9B,IAAK,sBAEH,YADAd,EAAKsC,wBAAwBxB,GAI/B,IAAK,mCAEH,YADAd,EAAKuC,2BAA2BzB,GAIlC,IAAK,0BAEH,YADAd,EAAKwC,4BAA4B1B,GAInC,IAAK,2BAEH,YADAd,EAAKyC,4BAA4B3B,GAInC,IAAK,QAEH,YADAd,EAAK0C,iBAAiB5B,GAIxB,QAIE,YAHId,EAAKF,QAAQV,SACfY,EAAKF,QAAQV,QAAQ0B,IAK7B,EAiBO6B,KAAAA,UAAY,EAAGtC,aACpBH,KAAKG,OAASA,GA1WKH,KAAOJ,QAAPA,EACAI,KAAUH,WAAVA,EAEfG,KAAKJ,QAAQX,WACfe,KAAKJ,QAAQX,UAAU,CAAEyD,eAAgB7C,EAAW6C,iBAEtD1C,KAAKH,WAAWR,UAAUW,KAAKX,WAC/BW,KAAKH,WAAWV,aAAaa,KAAKO,uBAClCP,KAAKH,WAAWN,aAAaU,GAAQD,KAAK2C,WAAW1C,IACrDD,KAAKU,aAAa,YACpB,CAEOkC,UAAAA,GACL,OAAW5C,KAACO,sBAAsB,CAAEsC,OAAQ,QAC9C,CAYU,sBAAMlC,GACdX,KAAKH,WAAWiD,OAClB,CAEUH,UAAAA,CAAW1C,GACfA,IAASD,KAAKC,OAChBD,KAAKC,KAAOA,EACRD,KAAKJ,QAAQL,cACfS,KAAKJ,QAAQL,aAAa,CAAEU,SAGlC,CAEUS,YAAAA,CAAaR,GACjBA,IAAWF,KAAKE,SAClBF,KAAKE,OAASA,EACVF,KAAKJ,QAAQJ,gBACfQ,KAAKJ,QAAQJ,eAAe,CAAEU,WAGpC,CAEU6C,qBAAAA,GACR,MAAMzC,EAAkBN,KAAKI,iBAAmBJ,KAAKK,oBACjDL,KAAKM,kBAAoBA,IAC3BN,KAAKM,gBAAkBA,EACnBN,KAAKJ,QAAQH,yBACfO,KAAKJ,QAAQH,wBAAwB,CAAEa,oBAG7C,CAEUQ,kBAAAA,CAAmBkC,GACvBA,EAAMC,qBACRjD,KAAKD,uBAAyBiD,EAAMC,mBAAmBlB,SAEnD/B,KAAKJ,QAAQF,gBACfM,KAAKJ,QAAQF,eAAe,CAC1BqC,SAAUiB,EAAMC,mBAAmBlB,WAI3C,CAEUhB,mBAAAA,CAAoBiC,GACxBhD,KAAKJ,QAAQP,WACfW,KAAKJ,QAAQP,UAAU,CACrB6D,OAAQ,KACRC,KAAM,QACN9B,QAAS2B,EAAMI,qBAAqBC,gBAG1C,CAEUrC,oBAAAA,CAAqBgC,GACzBhD,KAAKJ,QAAQP,WACfW,KAAKJ,QAAQP,UAAU,CACrB6D,OAAQ,OACRC,KAAM,OACN9B,QAAS2B,EAAMM,yBAAyBC,iBAG9C,CAEUtC,4BAAAA,CACR+B,GAEIhD,KAAKJ,QAAQV,SACfc,KAAKJ,QAAQV,QAAQ,CACnB2B,KAAM,2BACN2C,SACER,EAAMS,wCACHC,0BAGX,CAEU7B,cAAAA,CAAemB,GACnBhD,KAAKJ,QAAQ+D,YACf3D,KAAKJ,QAAQ+D,WAAW,CACtBC,SAAUZ,EAAMa,gBAAgBC,WAGtC,CAEU,0BAAM5C,CAAqB8B,GACnC,GACEe,OAAOC,UAAUC,eAAeC,KAC9BlE,KAAKJ,QAAQZ,YACbgE,EAAMxB,iBAAiBC,WAGzB,IAAI0C,IAAAA,EACF,MAAMC,EAGH,OAHSD,QACHnE,KAAKJ,QAAQZ,YAAYgE,EAAMxB,iBAAiBC,WACrDuB,EAAMxB,iBAAiB6C,aACxBF,EAAK,oCAGFG,EACc,iBAAXF,EAAsBG,KAAKC,UAAUJ,GAAU9C,OAAO8C,GAE/DpE,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQE,EACRG,UAAU,GAEd,CAAE,MAAOC,GACP1E,KAAKZ,QACH,sDAAuDsF,MAAAA,OAAAA,EAAAA,EAAarD,UACpE,CACEE,eAAgByB,EAAMxB,iBAAiBC,YAG3CzB,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQ,iCAAkCM,MAAAA,OAAAA,EAAAA,EAAarD,UACvDoD,UAAU,GAEd,KACK,CACL,GAAIzE,KAAKJ,QAAQ+E,0BAGf,YAFA3E,KAAKJ,QAAQ+E,0BAA0B3B,EAAMxB,kBAK/CxB,KAAKZ,QACH,yBAAyB4D,EAAMxB,iBAAiBC,qCAChD,CACEF,eAAgByB,EAAMxB,iBAAiBC,YAG3CzB,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,qBACNc,aAAcqB,EAAMxB,iBAAiBG,aACrCyC,OAAQ,yBAAyBpB,EAAMxB,iBAAiBC,qCACxDgD,UAAU,GAEd,CACF,CAEU7C,WAAAA,CAAYoB,GAAsB,CAElCf,iBAAAA,CAAkBe,GACtBhD,KAAKJ,QAAQgF,eACf5E,KAAKJ,QAAQgF,cAAc5B,EAAM6B,cAErC,CAEU3C,yBAAAA,CAA0Bc,GAC9BhD,KAAKJ,QAAQkF,uBACf9E,KAAKJ,QAAQkF,sBAAsB9B,EAAM+B,sBAE7C,CAEU5C,sBAAAA,CAAuBa,GAC3BhD,KAAKJ,QAAQoF,oBACfhF,KAAKJ,QAAQoF,mBAAmBhC,EAAMiC,mBAE1C,CAEU7C,uBAAAA,CAAwBY,GACY,aAAxCA,EAAMkC,oBAAoBzD,WAC5BzB,KAAKO,sBAAsB,CACzBsC,OAAQ,QACRsC,QAAS,IAAIC,WAAW,WAAY,CAAEvC,OAAQ,2BAI9C7C,KAAKJ,QAAQyF,qBACfrF,KAAKJ,QAAQyF,oBAAoBrC,EAAMkC,oBAE3C,CAEU7C,0BAAAA,CAA2BW,GAC/BhD,KAAKJ,QAAQ0F,wBACftF,KAAKJ,QAAQ0F,uBACXtC,EAAMuC,uCAGZ,CAEUjD,2BAAAA,CAA4BU,GAChChD,KAAKJ,QAAQ4F,yBACfxF,KAAKJ,QAAQ4F,wBAAwBxC,EAAMyC,8BAE/C,CAEUlD,2BAAAA,CAA4BS,GAChChD,KAAKJ,QAAQ8F,yBACf1F,KAAKJ,QAAQ8F,wBAAwB1C,EAAM2C,mBAE/C,CAEUnD,gBAAAA,CAAiBQ,GACzB,MAAM4C,EAAY5C,EAAM6C,YAAYC,WAC9BzE,EACJ2B,EAAM6C,YAAYxE,SAAW2B,EAAM6C,YAAYhD,QAAU,gBAEzC,0BAAd+C,EASJ5F,KAAKZ,QAAQ,iBAAiBiC,IAAW,CACvCuE,YACAG,KAAM/C,EAAM6C,YAAYE,KACxBC,aAAchD,EAAM6C,YAAYI,cAChCxF,QAASuC,EAAM6C,YAAYpF,UAZ3BT,KAAKO,sBAAsB,CACzBsC,OAAQ,QACRxB,QAASA,EACT8D,QAAS,IAAIe,MAAM,0BAWzB,CAuGQ9G,OAAAA,CAAQiC,EAAiB8D,GAC/BgB,QAAQhF,MAAME,EAAS8D,GACnBnF,KAAKJ,QAAQR,SACfY,KAAKJ,QAAQR,QAAQiC,EAAS8D,EAElC,CAEOiB,KAAAA,GACL,OAAWpG,KAACH,WAAW6C,cACzB,CAEO2D,MAAAA,GACL,MAAuB,cAAZrG,KAACE,MACd,CAMOoG,WAAAA,CAAYC,GACjBvG,KAAKH,WAAWyG,YAAYC,EAC9B,CAEOC,yBAAAA,GACL,OAAO9H,CACT,CAEO+H,0BAAAA,GACL,OAAO/H,CACT,CAEOgI,cAAAA,GACL,OAAO,CACT,CAEOC,eAAAA,GACL,OAAO,CACT,CAEOC,YAAAA,CAAaC,GACb7G,KAAKM,iBASVN,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,WACNiG,MAAOD,EAAO,OAAS,UACvB9E,SAAU/B,KAAKI,iBAEjBJ,KAAKK,oBAAsBL,KAAKI,eAChCJ,KAAK+C,yBAdHoD,QAAQY,KACuB,IAA7B/G,KAAKK,oBACD,8DACA,iFAYV,CAEO2G,oBAAAA,CAAqBC,GAC1BjH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,oBACNoG,QAEJ,CAEOC,eAAAA,CAAgBD,GACrBjH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,eACNoG,QAEJ,CAEOE,gBAAAA,GACLnH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,iBAEV,CAEOuG,yBAAAA,CAA0B1F,EAAoB2F,GACnDrH,KAAKH,WAAWiC,YAAY,CAC1BjB,KAAM,2BACNc,aAAcD,EACd4F,YAAaD,GAEjB,QCrboBE,EAYpB5H,WAAAA,CAAY6H,EAAgD,CAAE,GAPpDC,KAAAA,MAA+B,QAC/BC,qBAAoD,KAAI1H,KACxD2H,qBAAoD,KACpDC,KAAAA,kBAA8C,KAAI5H,KAClD6H,qBAAsD,KACtD3I,KAAAA,aAGR,EAAAc,KAAKd,QAAUsI,EAAOtI,OACxB,CAEU4I,KAAAA,CAAMC,GACV/H,KAAKd,SAASc,KAAKd,QAAQ6I,EACjC,CAMO1I,SAAAA,CAAU2I,GACfhI,KAAK4H,kBAAoBI,EACzB,MAAMP,EAAQzH,KAAKyH,MACnBzH,KAAKyH,MAAQ,GAETA,EAAMQ,OAAS,GAGjBC,eAAe,KACbT,EAAMU,QAAQH,IAGpB,CAEO7I,YAAAA,CAAa6I,GAClBhI,KAAK2H,qBAAuBK,EAC5B,MAAMvH,EAAUT,KAAK0H,qBACjBjH,GAGFyH,eAAe,KACbF,EAASvH,IAGf,CAEOlB,YAAAA,CAAayI,GAClBhI,KAAK6H,qBAAuBG,CAC9B,CAEUrF,UAAAA,CAAW1C,GAAUmI,IAAAA,EAC7BA,OAAAA,EAAIpI,KAAC6H,uBAALO,EAAAlE,UAA4BjE,EAC9B,CAEUoI,UAAAA,CAAW5H,GACa6H,IAAAA,EAA3BtI,KAAK0H,uBACR1H,KAAK0H,qBAAuBjH,SAC5B6H,EAAAtI,KAAK2H,uBAALW,EAAApE,KAAAlE,KAA4BS,GAEhC,CAEU8H,aAAAA,CAAc3H,GAClBZ,KAAK4H,kBACP5H,KAAK4H,kBAAkBhH,GAEvBZ,KAAKyH,MAAMe,KAAK5H,EAEpB,EAGc,SAAA6H,EAAYC,GAC1B,MAAOC,EAAYC,GAAkBF,EAAOG,MAAM,KAClD,IAAK,CAAC,MAAO,QAAQC,SAASH,GAC5B,MAAM,IAAIvH,MAAM,mBAAmBsH,KAGrC,MAAMK,EAAaC,OAAOC,SAASL,GACnC,GAAII,OAAOE,MAAMH,GACf,MAAU,IAAA3H,MAAM,wBAAwBwH,KAG1C,MAAO,CACLF,OAAQC,EACRI,aAEJ,CC7Ka,MAAAI,EAAkB,SCuFf,SAAAC,EAAmBpG,GACjC,QAASA,EAAMnC,IACjB,CCvFO,MAAMwI,EACX,sCAEc,SAAAC,EACd9B,GAAqB,IAAA+B,EAErB,MAAMC,EAA4C,CAChD3I,KAAMwI,OAGcI,EAAAC,EAAAC,EAAAC,EAAAC,EAmCtB,OAnCIrC,EAAOsC,YACTN,EAAeO,6BAA+B,CAC5CC,MAAO,CACLC,OAAQR,OAAFA,EAAEjC,EAAOsC,UAAUE,YAAjBP,EAAAA,EAAwBQ,OAChCC,cAAeR,OAAFA,EAAElC,EAAOsC,UAAUE,YAAjBN,EAAAA,EAAwBS,aACvCC,SAAgC,OAAxBT,EAAEnC,EAAOsC,UAAUE,YAAK,EAAtBL,EAAwBS,UAEpCC,IAAK,CACHC,SAA8B,OAAtBV,EAAEpC,EAAOsC,UAAUO,UAAG,EAApBT,EAAsBW,SAElCC,aAAc,CACZC,UAAwC,OAA/BZ,EAAErC,EAAOsC,UAAUU,mBAAY,EAA7BX,EAA+Ba,YAK5ClD,EAAOmD,qBACTnB,EAAeoB,sBAAwBpD,EAAOmD,oBAG5CnD,EAAOqD,mBACTrB,EAAesB,kBAAoBtD,EAAOqD,kBAGxCrD,EAAOuD,SACTvB,EAAewB,QAAUxD,EAAOuD,QAG9BxB,OAAJA,EAAI/B,EAAOsC,YAAPP,EAAkB0B,SACpBzB,EAAe0B,YAAc,CAC3BhI,OAAQsE,EAAOsC,UAAUmB,OAAO/H,OAChCiI,QAAS3D,EAAOsC,UAAUmB,OAAOE,UAI9B3B,CACT,CC/BM,MAAO4B,UAA4B7D,EAKvC5H,WAAAA,CACmB0L,EACjB3I,EACA4I,EACAC,GAEAC,QAAQxL,KALSqL,mBALH3I,oBAAc,EAAA1C,KACdsL,iBACAC,EAAAA,KAAAA,oBAGGvL,KAAMqL,OAANA,EAMjBrL,KAAK0C,eAAiBA,EACtB1C,KAAKsL,YAAcA,EACnBtL,KAAKuL,aAAeA,EAEpBvL,KAAKqL,OAAOI,iBAAiB,QAASzI,IAIpC0I,WACE,IACE1L,KAAKqI,WAAW,CACdxF,OAAQ,QACRxB,QAAS,mDACT8D,QAASnC,IAEb,KAIJhD,KAAKqL,OAAOI,iBAAiB,QAASzI,IACpChD,KAAKqI,WACY,MAAfrF,EAAM+C,KACF,CACElD,OAAQ,QACRsC,QAASnC,GAEX,CACEH,OAAQ,QACRxB,QACE2B,EAAMH,QAAU,2CAClBsC,QAASnC,MAKnBhD,KAAKqL,OAAOI,iBAAiB,UAAWzI,IACtC,IACE,MAAMpC,EAAc2D,KAAKoH,MAAM3I,EAAM4I,MACrC,IAAKxC,EAAmBxI,GAMtB,YALAZ,KAAK8H,MAAM,CACTjH,KAAM,gBACNQ,QAAS,gCACTuK,KAAM5I,EAAM4I,OAIhB5L,KAAKuI,cAAc3H,EACrB,CAAE,MAAOO,GACPnB,KAAK8H,MAAM,CACTjH,KAAM,gBACNQ,QAAS,iCACTF,MAAOA,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,GACvDyK,KAAM5I,EAAM4I,MAEhB,GAEJ,CAEO,mBAAaC,CAClBrE,GAEA,IAAI6D,EAA2B,KAE/B,IAAI,IAAAS,EAAAvC,EAAAwC,EACF,MAAMC,EAAsBF,OAAhBA,EAAGtE,EAAOwE,QAAMF,EA/EX,0BAgFjB,IAAIG,EAEJ,MAAMd,GAA0B,OAAhB5B,EAAA/B,EAAOsC,YAAiB,OAARP,EAAhBA,EAAkB0B,aAAM,EAAxB1B,EAA0B4B,UAAWhC,EAC/CjG,GAAyB6I,OAAhBA,EAAAvE,EAAOsC,YAAiB,OAARiC,EAAhBA,EAAkBd,aAAM,EAAxBc,EAA0B7I,SAAU,SAEnD,GAAIsE,EAAO0E,UAAW,CACpB,MAAMC,EAAY3E,EAAO0E,UAAUpD,SAAS,KAAO,IAAM,IACzDmD,EAAM,GAAGzE,EAAO0E,YAAYC,WAAmBjJ,aAAkBiI,GACnE,MACEc,EAAM,GAAGD,qCAA4BxE,EAAO4E,kBAAkBlJ,aAAkBiI,IAGlF,MAAMkB,EAAY,CA7FF,UA8FZ7E,EAAO8E,eACTD,EAAU7D,KAAK,UAAUhB,EAAO8E,iBAElCjB,EAAS,IAAIkB,UAAUN,EAAKI,GAE5B,MAAMG,YAA+BC,QAEnC,CAACC,EAASC,KACVtB,EAAQI,iBACN,OACA,SAAKmB,EACH,MAAMpD,EAAiBF,EAAmB9B,GAE1CoF,OAAAA,EAAAvB,IAAAuB,EAAQC,KAAKtI,KAAKC,UAAUgF,KAE9B,CAAEsD,MAAM,IAGVzB,EAAQI,iBAAiB,QAASzI,IAIhC0I,WAAW,IAAMiB,EAAO3J,GAAQ,KAGlCqI,EAAQI,iBAAiB,QAASkB,GAElCtB,EAAQI,iBACN,UACCzI,IACC,MAAM3B,EAAUkD,KAAKoH,MAAM3I,EAAM4I,MAE5BxC,EAAmB/H,KAIH,qCAAjBA,EAAQR,KACV6L,EAAQrL,EAAQkE,wCAEhBY,QAAQY,KACN,0DAIN,CAAE+F,MAAM,OAINC,gBACJA,EAAeC,0BACfA,EAAyBC,wBACzBA,GACET,EAEElB,EAAc7C,EAAYwE,MAAAA,EAAAA,EAA2B,aACrD1B,EAAe9C,EAAYuE,GAEjC,WAAW5B,EACTC,EACA0B,EACAzB,EACAC,EAEJ,CAAE,MAAOpK,GAAO+L,IAAAA,EAEd,MADM,OAANA,EAAA7B,IAAA6B,EAAQpK,QACF3B,CACR,CACF,CAEO2B,KAAAA,GACL9C,KAAKqL,OAAOvI,OACd,CAEOhB,WAAAA,CAAYT,GACjBrB,KAAKqL,OAAOwB,KAAKtI,KAAKC,UAAUnD,GAClC,CAEO,iBAAMiF,CAAYC,GACvBJ,QAAQY,KACN,gDAAgDR,8CAEpD,EC7LI,SAAU4G,EAAoBC,GAClC,MAAMC,EAAS,IAAI1O,WAAWyO,GAG9B,OADmBE,OAAOC,KAAKjM,OAAOkM,gBAAgBH,GAExD,UAEgBI,EAAoBC,GAClC,MAAMC,EAAeL,OAAOM,KAAKF,GAC3BG,EAAMF,EAAa1F,OACnB6F,EAAQ,IAAInP,WAAWkP,GAC7B,IAAK,IAAIE,EAAI,EAAGA,EAAIF,EAAKE,IACvBD,EAAMC,GAAKJ,EAAaK,WAAWD,GAErC,OAAOD,EAAMT,MACf,CCfA,MAAMY,EAAW,IAAIC,IAEL,SAAAC,EAA0BC,EAAcC,GACtD,OAAcC,MAAAA,EAAuBC,KACnC,MAAMC,EAAYP,EAASQ,IAAIL,GAC/B,GAAII,EACF,OAAOF,EAAQI,UAAUF,GAI3B,GAAID,EACF,IAGE,aAFMD,EAAQI,UAAUH,QACxBN,EAASU,IAAIP,EAAMG,EAErB,CAAE,MAAOpN,GACP,UAAUC,MACR,sBAAsBgN,+BAAkCG,aAAgBpN,IAE5E,CAGF,MAAMyN,EAAO,IAAIC,KAAK,CAACR,GAAa,CAAExN,KAAM,2BACtCiO,EAAUC,IAAIC,gBAAgBJ,GACpC,IAGE,aAFMN,EAAQI,UAAUI,QACxBb,EAASU,IAAIP,EAAMU,EAErB,CAAE,MAAAG,GACAF,IAAIG,gBAAgBJ,EACtB,CAEA,IAIE,MACMK,EAAY,sCADH5B,KAAKc,WAEdC,EAAQI,UAAUS,GACxBlB,EAASU,IAAIP,EAAMe,EACrB,CAAE,MAAOhO,GACP,MAAU,IAAAC,MACR,sBAAsBgN,8IAE1B,EAEJ,CC3CO,MAAMgB,EAAwBjB,EACnC,oBAEA,g2HCkCI,MAAOkB,UAAyB9H,EAepC5H,WAAAA,CACE2P,EACA5M,EACA4I,EACAC,EACA/D,EAAgD,CAAA,GAEhDgE,MAAMhE,GAAQxH,KArBT0C,oBAAc,EAAA1C,KACLsL,iBAAW,EAAAtL,KACXuL,kBAAY,EAAAvL,KAEpBsP,UAAI,EAAAtP,KACJuP,aAAc,EACdC,KAAAA,aAAe,EACfC,KAAAA,oBAA2C,KAC3CC,KAAAA,cAAoC,GACpCC,KAAAA,eAAgC,KAAI3P,KAEpC4P,eAAsC,KAAI5P,KAC1C6P,oBAAsD,KAU5D7P,KAAKsP,KAAOA,EACZtP,KAAK0C,eAAiBA,EACtB1C,KAAKsL,YAAcA,EACnBtL,KAAKuL,aAAeA,EAEpBvL,KAAK8P,yBACP,CAEO,mBAAajE,CAClBrE,GAEA,IAAIuI,EAGJ,GAAI,sBAAuBvI,GAAUA,EAAOuI,kBAE1CA,EAAoBvI,EAAOuI,sBACtB,MAAI,YAAavI,KAAUA,EAAO4E,QAkCvC,MAAM,IAAIhL,MACR,yEAjCF,IAAI,IAAAmI,EAAAwC,EAAAD,EACF,MAAMX,GAA0B,OAAhB5B,EAAA/B,EAAOsC,YAAPP,OAAgBA,EAAhBA,EAAkB0B,aAAlB1B,EAAAA,EAA0B4B,UAAWhC,EAC/CjG,GAAyB6I,OAAhBA,EAAAvE,EAAOsC,mBAASiC,EAAhBA,EAAkBd,eAAlBc,EAA0B7I,SAAU,SAG7C+I,EAAM,GAvDOD,EAqDeF,OAAhBA,EAAGtE,EAAOwE,QAAMF,EAxDjB,4BAIhBE,EAAOgE,QAAQ,YAAa,qDAsDkCxI,EAAO4E,kBAAkBlJ,aAAkBiI,IACpG3H,QAAiByM,MAAMhE,GAE7B,IAAKzI,EAAS0M,GACZ,MAAU,IAAA9O,MACR,2BAA2BoC,EAAStD,UAAUsD,EAAS2M,cAO3D,GAFAJ,SADmBvM,EAAS4M,QACHC,OAEpBN,EACH,MAAM,IAAI3O,MAAM,0CAEpB,CAAE,MAAOD,GACP,IAAImP,EAAMnP,aAAiBC,MAAQD,EAAME,QAAUC,OAAOH,GAM1D,MALIA,aAAiBC,OAASD,EAAME,QAAQyH,SAAS,SACnDwH,EACE,gGAGE,IAAIlP,MACR,gDAAgDoG,EAAO4E,YAAYkE,IAEvE,CAKF,CArFJ,IAA2BtE,EAuFvB,MAAMsD,EAAO,IAAIiB,EAEjB,IAEE,MAAM7N,EAAiB,QAAQ8N,KAAKC,QAC9BnF,EAAc7C,EAAY,aAC1B8C,EAAe9C,EAAY,aAC3B5I,EAAa,IAAIwP,EACrBC,EACA5M,EACA4I,EACAC,EACA/D,GAIIkJ,EAAalJ,EAAOkJ,YA3GD,kCA6HVC,IAAAA,QAfTrB,EAAKsB,QAAQF,EAAYX,SAGrB,IAAAtD,QAAcC,IACtB,GAAI7M,EAAW0P,YACb7C,QACK,CACL,MAAMmE,EAAcA,KAClBvB,EAAKwB,IAAIC,EAAUC,UAAWH,GAC9BnE,KAEF4C,EAAK2B,GAAGF,EAAUC,UAAWH,EAC/B,IAGEvB,EAAKlB,OACPvO,EAAW6C,gBAC6B,OAAtCiO,EAAArB,EAAKlB,KAAK8C,MAAM,6BAAsB,EAAtCP,EAAyC,KAAMrB,EAAKlB,YAIlDkB,EAAK6B,iBAAiBC,sBAAqB,GAEjD,MAAM5H,EAAiBF,EAAmB9B,GAS1C,OAPA3H,EAAWiI,MAAM,CACfjH,KAAMwI,EACNhI,QAASmI,UAGL3J,EAAWiC,YAAY0H,GAEtB3J,CACT,CAAE,MAAOsB,GAEP,YADMmO,EAAKjH,aACLlH,CACR,CACF,CAEQ2O,uBAAAA,GAAuB,IAAAhQ,EAC7BE,KAAAA,KAAKsP,KAAK2B,GAAGF,EAAUC,UAAWxQ,iBAChCV,EAAKyP,aAAc,EACnBpJ,QAAQ4B,KAAK,wBACf,GAEA/H,KAAKsP,KAAK2B,GAAGF,EAAUM,aAAcxO,IACnC7C,KAAKuP,aAAc,EACnBvP,KAAKqI,WAAW,CACdxF,OAAQ,QACRsC,QAAS,IAAIC,WAAW,QAAS,CAAEvC,OAAQA,MAAAA,OAAAA,EAAAA,EAAQyO,iBAIvDtR,KAAKsP,KAAK2B,GAAGF,EAAUQ,uBAAwBC,IACzCA,IAAUC,EAAgBJ,eAC5BrR,KAAKuP,aAAc,EACnBvP,KAAKqI,WAAW,CACdxF,OAAQ,QACRxB,QAAS,uCAAuCmQ,IAChDrM,QAAS,IAAIe,MAAM,iCAMzBlG,KAAKsP,KAAK2B,GACRF,EAAUW,aACV,CAACC,EAAqBC,KACpB,IACE,MAAMvQ,EAAUkD,KAAKoH,OAAM,IAAIkG,aAAcC,OAAOH,IAGpD,GAAqB,UAAjBtQ,EAAQR,KACV,OAGEuI,EAAmB/H,GACrBrB,KAAKuI,cAAclH,GAEnB8E,QAAQY,KAAK,iCAAkC1F,EAEnD,CAAE,MAAOF,GACPgF,QAAQY,KAAK,yCAA0C5F,GACvDgF,QAAQY,KAAK,gBAAgB,IAAI8K,aAAcC,OAAOH,GACxD,IAIJ3R,KAAKsP,KAAK2B,GACRF,EAAUgB,gBACVvR,eACEwR,EACAC,EACAC,GAEA,GACEF,EAAMG,OAASC,EAAMC,KAAKC,OAC1BJ,EAAYK,SAASzJ,SAAS,SAC9B,CAEA,MAAM0J,EAAmBR,EACnBS,EAAeD,EAAiBE,SAKtC,GAJAD,EAAaE,UAAW,EACxBF,EAAaG,UAAW,EAGpB9S,EAAK6P,gBAAkB8C,EAAaI,UACtC,UACQJ,EAAaI,UAAU/S,EAAK6P,eACpC,CAAE,MAAOxO,GACPgF,QAAQY,KACN,qDACA5F,EAEJ,CAIFsR,EAAaK,MAAMC,QAAU,OAC7BC,SAASC,KAAKC,YAAYT,GAG1B3S,EAAK4P,cAAclH,KAAKiK,GAGU,IAA9B3S,EAAK4P,cAAczH,SAErBnI,MAAAA,EAAKZ,SAALY,EAAKZ,QAAU,CAAE2B,KAAM,+BAInBf,EAAKqT,kBAAkBX,EAC/B,CACF,GAGFxS,KAAKsP,KAAK2B,GACRF,EAAUqC,sBACV5S,eAAO6S,GAEHvT,EAAK6C,WADH0Q,EAASpL,OAAS,GAElBoL,EAAS,GAAGd,SAASe,WAAW,SAAW,WAG7B,YAEpB,GAGFtT,KAAKsP,KAAK2B,GACRF,EAAUwC,wBACTrB,IAAkCsB,IAAAA,EACT,OAAxBA,EAAItB,EAAYK,WAAZiB,EAAsBF,WAAW,UACnCtT,KAAKqI,WAAW,CACdxF,OAAQ,QACRsC,QAAS,IAAIC,WAAW,QAAS,CAAEvC,OAAQ,0BAKrD,CAEOC,KAAAA,GACL,GAAI9C,KAAKuP,YAAa,CACpB,IAEEvP,KAAKsP,KAAK6B,iBAAiBsC,uBAAuBtL,QAChDuL,IACMA,EAAY1B,OACd0B,EAAY1B,MAAM2B,QAI1B,CAAE,MAAOxS,GACPgF,QAAQY,KAAK,+BAAgC5F,EAC/C,CAGInB,KAAKyP,sBACPzP,KAAKyP,oBAAoB3M,QAAQ8Q,MAAMzS,IACrCgF,QAAQY,KAAK,uCAAwC5F,KAEvDnB,KAAKyP,oBAAsB,MAI7BzP,KAAK0P,cAAcvH,QAAQ0L,IACrBA,EAAQC,YACVD,EAAQC,WAAWC,YAAYF,KAGnC7T,KAAK0P,cAAgB,GAErB1P,KAAKsP,KAAKjH,YACZ,CACF,CAEO,iBAAMvG,CAAYT,GACvB,GAAKrB,KAAKuP,aAAgBvP,KAAKsP,KAAK6B,kBAQpC,KAAI,qBAAsB9P,GAK1B,IACE,MACMuK,GADU,IAAIoI,aACCC,OAAO1P,KAAKC,UAAUnD,UAErCrB,KAAKsP,KAAK6B,iBAAiB+C,YAAYtI,EAAM,CAAEuI,UAAU,GACjE,CAAE,MAAOhT,GACPnB,KAAK8H,MAAM,CACTjH,KAAM,qBACNQ,QAAS,CACPA,UACAF,WAGJgF,QAAQhF,MAAM,qCAAsCA,EACtD,OA1BEgF,QAAQY,KACN,kEA0BN,CAGOqN,OAAAA,GACL,OAAOpU,KAAKsP,IACd,CAEO,iBAAMhJ,CAAYC,GACvB,IAAKvG,KAAKuP,cAAgBvP,KAAKsP,KAAK6B,iBAIlC,YAHAhL,QAAQY,KACN,2EAMJ,MAAMsN,EAAsBrU,KAAKsP,KAAK6B,iBAAiBmD,oBACrDlC,EAAMmC,OAAOC,YAGf,GAAIH,MAAAA,GAAAA,EAAqBrC,MACvB,IAEMzL,QACI8N,EAAoBrC,MAAMyC,aAE1BJ,EAAoBrC,MAAM0C,QAEpC,CAAE,MAAOC,SAED3U,KAAKsP,KAAK6B,iBAAiBC,sBAAsB7K,EACzD,YAGUvG,KAACsP,KAAK6B,iBAAiBC,sBAAsB7K,EAE3D,CAEQ,uBAAM4M,CAAkBnB,GAC9B,IAEE,MAAM4C,EAAe,IAAIC,aACzB7U,KAAKyP,oBAAsBmF,EAG3B5U,KAAK4P,eAAiBgF,EAAaE,iBACnC9U,KAAK4P,eAAemF,QAAU,KAC9B/U,KAAK4P,eAAeoF,sBAAwB,GAG5C,MAAMC,EAAc,IAAIC,YAAY,CAAClD,EAAMmD,mBAGrCjS,EAAS0R,EAAaQ,wBAAwBH,GAGpD/R,EAAO0N,QAAQ5Q,KAAK4P,sBAEdR,EAAsBwF,EAAaS,cACzC,MAAM/G,EAAU,IAAIgH,iBAAiBV,EAAc,qBAGnD5U,KAAK4P,eAAegB,QAAQtC,GAG5BA,EAAQiH,KAAKC,YAAY,CACvB3U,KAAM,YACN6H,OAAQ1I,KAAKuL,aAAa7C,OAC1BK,WAAY/I,KAAKuL,aAAaxC,aAIhCuF,EAAQiH,KAAKE,UAAazS,IACxB,MAAO0S,EAAWC,GAAa3S,EAAM4I,KAKrC,GAAI+J,EAFoB,IAES,CAE/B,MAAMC,EAAczI,EAAoBuI,EAAUrI,QAG5CwI,EAAU7V,KAAKwP,eAGrBxP,KAAKuI,cAAc,CACjB1H,KAAM,QACNiV,YAAa,CACXC,cAAeH,EACf7T,SAAU8T,IAGhB,GAIF3S,EAAO0N,QAAQtC,EACjB,CAAE,MAAOnN,GACPgF,QAAQY,KAAK,kCAAmC5F,EAClD,CACF,CAEO6U,cAAAA,CAAe7V,GACpBH,KAAK0P,cAAcvH,QAAQ0L,IACzBA,EAAQ1T,OAASA,GAErB,CAEO,0BAAM8V,CAAqBC,GAChC,KAAM,cAAeC,iBAAiBnS,WACpC,MAAU,IAAA5C,MAAM,8CAIlB,MAAMgV,EAAWpW,KAAK0P,cAAc2G,IAAI7V,eAAMqT,GAC5C,UACQA,EAAQhB,UAAUqD,EAC1B,CAAE,MAAO/U,GAEP,MADAgF,QAAQhF,MAAM,2CAA4CA,GACpDA,CACR,CACF,SAEMsL,QAAQ6J,IAAIF,GAGlBpW,KAAK2P,eAAiBuG,CACxB,CAEO,yBAAMK,CAAoBL,GAC/B,IAAKlW,KAAKuP,cAAgBvP,KAAKsP,KAAK6B,iBAClC,MAAM,IAAI/P,MACR,0EAIJ,IAEE,MAAMoV,EACJxW,KAAKsP,KAAK6B,iBAAiBmD,oBAAoBlC,EAAMmC,OAAOC,YAGhC,MAA1BgC,GAAAA,EAA4BxE,cACxBwE,EAA2BxE,MAAM2B,aACjC3T,KAAKsP,KAAK6B,iBAAiBsF,eAC/BD,EAA2BxE,QAK/B,MAAM0E,EAA0C,CAC9CR,SAAU,CAAES,MAAOT,GACnBU,kBAAkB,EAClBC,kBAAkB,EAClBC,iBAAiB,EACjBC,aAAc,CAAEC,MAAO,IAInBC,QAAmBC,EAAsBR,SAGrC1W,KAACsP,KAAK6B,iBAAiBgG,aAAaF,EAAY,CACxD7I,KAAM,aACNlL,OAAQkP,EAAMmC,OAAOC,YAEzB,CAAE,MAAOrT,GACPgF,QAAQhF,MAAM,iCAAkCA,GAGhD,UACYnB,KAACsP,KAAK6B,iBAAiBC,sBAAqB,EACxD,CAAE,MAAOgG,GACPjR,QAAQhF,MACN,0DACAiW,EAEJ,CAEA,MAAMjW,CACR,CACF,CAEOsF,0BAAAA,GACL,OAAKzG,KAAK4P,gBAEcyH,WAAnBxH,sBAAL7P,KAAK6P,oBAAwB,IAAIlR,WAC/BqB,KAAK4P,eAAe0H,oBAEtBtX,KAAK4P,eAAe2H,qBAAqBvX,KAAK6P,qBACnC7P,KAAC6P,qBANyB,IAOvC,ECrhBKrP,eAAegX,EACpBhQ,GAEA,MAAMiQ,EAlBR,SAAiCjQ,GAE/B,OAAIA,EAAOiQ,eACFjQ,EAAOiQ,eAIZ,sBAAuBjQ,GAAUA,EAAOuI,kBACnC,SAIF,WACT,CAKyB2H,CAAwBlQ,GAE/C,OAAQiQ,GACN,IAAK,YACH,OAAOrM,EAAoBS,OAAOrE,GACpC,IAAK,SACH,OAAO6H,EAAiBxD,OAAOrE,GACjC,QACE,UAAUpG,MAAM,4BAA4BqW,KAElD,UCpCgBE,IACd,MACE,CACE,iBACA,mBACA,iBACA,OACA,SACA,QACA7O,SAAS8O,UAAUC,WAEpBD,UAAUE,UAAUhP,SAAS,QAAU,eAAgBkK,QAE5D,gBCVsB+E,EACpBC,EAA2B,CACzBC,QAAS,EAETC,QAAS,MAGX,IAAIC,EAAQH,EAAYC,YACDG,EAAvB,GDKO,WAAWC,KAAKT,UAAUE,WCJ/BK,EAA2BC,OAAtBA,EAAGJ,EAAYE,SAAOE,EAAID,OACtBR,GAAAA,IAAe,KAAAW,EACxBH,EAAuBG,OAAlBA,EAAGN,EAAYO,KAAGD,EAAIH,CAC7B,CAEIA,EAAQ,SACA,IAAA1L,QAAQC,GAAWhB,WAAWgB,EAASyL,GAErD,OCfaK,UAAyB5Z,EAC7B,yBAAa6Z,CAClB7Y,GAEA,MAAM8Y,EAAc9Z,EAAiBC,eAAee,GAEhD8Y,EAAYlZ,gBACdkZ,EAAYlZ,eAAe,CAAEU,OAAQ,eAEnCwY,EAAYjZ,yBACdiZ,EAAYjZ,wBAAwB,CAAEa,iBAAiB,IAErDoY,EAAYnZ,cACdmZ,EAAYnZ,aAAa,CAAEU,KAAM,cAE/ByY,EAAYjZ,yBACdiZ,EAAYjZ,wBAAwB,CAAEa,iBAAiB,IAGzD,IAAIT,EAAoC,KACxC,IAGE,aAFMkY,EAAWW,EAAYC,iBAC7B9Y,QAAmB2X,EAAiB5X,GACzB,IAAA4Y,EAAiBE,EAAa7Y,EAC3C,CAAE,MAAOsB,GAAO,IAAAyX,EAKd,MAJIF,EAAYlZ,gBACdkZ,EAAYlZ,eAAe,CAAEU,OAAQ,iBAE7B,OAAV0Y,EAAA/Y,IAAA+Y,EAAY9V,QACN3B,CACR,CACF,EC1BF,MAGM0X,EAAqB,CACzBjC,kBAAkB,EAClBC,kBAAkB,EAElBC,iBAAiB,EAEjBC,aAAc,CAAEC,MAAO,UAGZ8B,EACJ,mBAAajN,EAAO9C,WACzBA,EAAUL,OACVA,EAAMqQ,8BACNA,EAA6BC,cAC7BA,EAAaC,aACbA,EAAYC,kBACZA,IAEA,IAAI/T,EAA+B,KAC/BgU,EAAkC,KAEtC,IACE,MAAMvZ,EAAOb,EACXgK,CAAAA,WAAY,CAAEiO,MAAOjO,IAClB8P,GAGL,GAAIlB,KAAiBoB,EAA+B,CAClD,MAEMK,SADE9L,OAAOsK,UAAUyB,aAAaC,oBACDC,KACnCC,GAGa,eAAXA,EAAErH,MACF,CAAC,SAAU,YAAa,YAAYoH,KAAKE,GACvCD,EAAEE,MAAMC,cAAc7Q,SAAS2Q,KAGjCL,IACFxZ,EAAQsW,SAAW,CAAEc,MAAOoC,EAAYlD,UAE5C,CAEI8C,IACFpZ,EAAQsW,SAAW4C,EAAMc,sBAAsBZ,IAGjD,MAAMa,EACJjC,UAAUyB,aAAaS,0BAA0B/Q,WAEnD5D,EAAU,IAAImI,OAAOuH,aACnBgF,EAA+B,CAAE9Q,cAAe,CAAA,GAElD,MAAMgR,EAAW5U,EAAQ2P,iBACzB,IAAK+E,EAA8B,CAEjC,MAAMG,EAAmBd,GA3D/B,0GA4DY/T,EAAQkQ,aAAa3G,UAAUsL,EACvC,OACM5K,EACJjK,EAAQkQ,aACR4D,MAAAA,OAAAA,EAAAA,EAAkC,mBAGpC,MAAMgB,EAAWlb,EAAA,CAAKmb,gBAAgB,GAASta,GAC/CuZ,QAAoBvB,UAAUyB,aAAac,aAAa,CACtDC,MAAOH,IAGT,MAAM/W,EAASiC,EAAQiQ,wBAAwB+D,GACzC7K,EAAU,IAAIgH,iBAAiBnQ,EAAS,qBAQ9C,OAPAmJ,EAAQiH,KAAKC,YAAY,CAAE3U,KAAM,YAAa6H,SAAQK,eAEtD7F,EAAO0N,QAAQmJ,GACfA,EAASnJ,QAAQtC,SAEXnJ,EAAQkV,SAEP,IAAIvB,EAAM3T,EAAS4U,EAAUzL,EAAS6K,EAAajW,EAC5D,CAAE,MAAO/B,GAAOmZ,IAAAA,EAAAC,EAKd,MAJAD,OAAAA,EAAAnB,IAAAmB,EAAaE,YAAYrS,QAAQ6J,IAC/BA,EAAM2B,SAED,OAAP4G,EAAApV,IAAAoV,EAASzX,QACH3B,CACR,CACF,CAGQ,4BAAOyY,CACbZ,GAEA,GAAKA,EAGL,OAAOrB,IAAgB,CAAEX,MAAOgC,GAAkB,CAAErC,MAAOqC,EAC7D,CAEArZ,WAAAA,CACkBwF,EACA4U,EACAzL,EACT6K,EACCsB,QAJQtV,aAAA,EAAAnF,KACA+Z,cACAzL,EAAAA,KAAAA,oBACT6K,iBAAA,EAAAnZ,KACCya,uBAJQ,EAAAza,KAAOmF,QAAPA,EACAnF,KAAQ+Z,SAARA,EACA/Z,KAAOsO,QAAPA,EACTtO,KAAWmZ,YAAXA,EACCnZ,KAAiBya,kBAAjBA,CACP,CAEI,WAAM3X,GACX9C,KAAKmZ,YAAYqB,YAAYrS,QAAQ6J,IACnCA,EAAM2B,SAER3T,KAAKya,kBAAkBpS,mBACjBrI,KAAKmF,QAAQrC,OACrB,CAEO4X,QAAAA,CAASnU,GACdvG,KAAKsO,QAAQiH,KAAKC,YAAY,CAAE3U,KAAM,WAAY0F,WACpD,CAEO,oBAAMoU,CAAe3B,GAC1B,IAEE,MAAMpZ,EAAOb,EACR8Z,CAAAA,EAAAA,GAGDG,IACFpZ,EAAQsW,SAAW4C,EAAMc,sBAAsBZ,IAIjD,MAAMiB,EAAWlb,EAAA,CAAKmb,gBAAgB,GAASta,GAGzCgb,QAAuBhD,UAAUyB,aAAac,aAAa,CAC/DC,MAAOH,IAITja,KAAKmZ,YAAYqB,YAAYrS,QAAQ6J,IACnCA,EAAM2B,SAER3T,KAAKya,kBAAkBpS,aAGvBrI,KAAKmZ,YAAcyB,EACnB5a,KAAKya,kBACHza,KAAKmF,QAAQiQ,wBAAwBwF,GAGvC5a,KAAKya,kBAAkB7J,QAAQ5Q,KAAK+Z,SACtC,CAAE,MAAO5Y,GAEP,MADAgF,QAAQhF,MAAM,iCAAkCA,GAC1CA,CACR,CACF,ECrKK,MAAM0Z,EAA2B1M,EACtC,uBAEA,i8ECEW,MAAA2M,EACJ,mBAAajP,EAAO9C,WACzBA,EAAUL,OACVA,EAAMiH,eACNA,EAAcsJ,aACdA,IAEA,IAAI9T,EAA+B,KAC/BsN,EAAwC,KAC5C,IACEtN,EAAU,IAAI0P,aAAa,CAAE9L,eAC7B,MAAMgR,EAAW5U,EAAQ2P,iBACnBiG,EAAO5V,EAAQ6V,aAGrBvI,EAAe,IAAIH,MACnBG,EAAawI,IAAM,GACnBxI,EAAayI,OACbzI,EAAaE,UAAW,EACxBF,EAAaK,MAAMC,QAAU,OAE7BC,SAASC,KAAKC,YAAYT,GAG1B,MAAM0I,EAAchW,EAAQiW,+BAC5B3I,EAAa4I,UAAYF,EAAYG,OAErCP,EAAKnK,QAAQmJ,GACbA,EAASnJ,QAAQuK,SAEXN,EACJ1V,EAAQkQ,aACI,MAAZ4D,OAAY,EAAZA,EAAqC,sBAEvC,MAAM3K,EAAU,IAAIgH,iBAAiBnQ,EAAS,wBAmB9C,OAlBAmJ,EAAQiH,KAAKC,YAAY,CAAE3U,KAAM,YAAa6H,WAC9C4F,EAAQsC,QAAQmK,SAEV5V,EAAQkV,SAGV1K,GAAkB8C,EAAaI,iBAC3BJ,EAAaI,UAAUlD,GAGb,IAAImL,EACpB3V,EACA4U,EACAgB,EACAzM,EACAmE,EAIJ,CAAE,MAAOtR,GAAO,IAAAoa,EAAAC,EAUd,MARID,OAAJA,EAAI9I,IAAA8I,EAAczH,YAChBrB,EAAaqB,WAAWC,YAAYtB,GAE1B,OAAZ+I,EAAA/I,IAAA+I,EAAcC,QACVtW,GAA6B,WAAlBA,EAAQqM,aACfrM,EAAQrC,QAGV3B,CACR,CACF,CAEAxB,WAAAA,CACkBwF,EACA4U,EACAgB,EACAzM,EACAmE,QAJAtN,aAAA,EAAAnF,KACA+Z,cAAA,EAAA/Z,KACA+a,UAAA,EAAA/a,KACAsO,aACAmE,EAAAA,KAAAA,kBAJA,EAAAzS,KAAOmF,QAAPA,EACAnF,KAAQ+Z,SAARA,EACA/Z,KAAI+a,KAAJA,EACA/a,KAAOsO,QAAPA,EACAtO,KAAYyS,aAAZA,CACf,CAEI,qBAAMiJ,CAAgBxF,GAC3B,KAAM,cAAeC,iBAAiBnS,WACpC,MAAU,IAAA5C,MAAM,oDAIZpB,KAAKyS,aAAaI,UAAUqD,GAAY,GAChD,CAEO,WAAMpT,GAEP9C,KAAKyS,aAAaqB,YACpB9T,KAAKyS,aAAaqB,WAAWC,YAAY/T,KAAKyS,cAEhDzS,KAAKyS,aAAagJ,cACRzb,KAACmF,QAAQrC,OACrB,QCrFW6Y,UAA0B/c,EAC9B,yBAAa6Z,CAClB7Y,OAAuBgc,EAEvB,MAAMlD,EAAc9Z,EAAiBC,eAAee,GAEhD8Y,EAAYlZ,gBACdkZ,EAAYlZ,eAAe,CAAEU,OAAQ,eAEnCwY,EAAYjZ,yBACdiZ,EAAYjZ,wBAAwB,CAAEa,iBAAiB,IAGzD,IAAIub,EAAsB,KACtBhc,EAAoC,KACpCic,EAAwB,KACxBC,EAA6C,KAE7CC,EAAoC,KACxC,GAAuBJ,OAAvBA,EAAIhc,EAAQqc,cAAWL,EACrB,IACEI,QAAiBpE,UAAUoE,SAASE,QAAQ,SAC9C,CAAE,MAAOC,GAAI,CAKf,IAAIC,IAAAA,EA6BF,OA1BAL,QAA+BnE,UAAUyB,aAAac,aAAa,CACjEC,OAAO,UAGHrC,EAAWW,EAAYC,iBAC7B9Y,QAAmB2X,EAAiB5X,IACnCic,EAAOC,SAAgBrP,QAAQ6J,IAAI,CAClCwC,EAAMjN,OAAM9M,EACPc,CAAAA,EAAAA,EAAWyL,aACdyN,8BAA+BnZ,EAAQmZ,8BACvCC,cAAepZ,EAAQoZ,cACvBC,aAAcrZ,EAAQqZ,aACtBC,kBAAmBtZ,EAAQsZ,qBAE7B4B,EAAOjP,OAAM9M,KACRc,EAAW0L,aACdoE,CAAAA,eAAgB/P,EAAQ+P,eACxBsJ,aAAcrZ,EAAQqZ,yBAI1BmD,EAAAL,IAAAK,EAAwB5B,YAAYrS,QAAQ6J,IAC1CA,EAAM2B,SAERoI,EAAyB,KAElB,IAAIJ,EACTjD,EACA7Y,EACAgc,EACAC,EACAE,EAEJ,CAAE,MAAO7a,GAAOkb,IAAAA,EAAAzD,EAAA0D,EAAAC,EACV7D,EAAYlZ,gBACdkZ,EAAYlZ,eAAe,CAAEU,OAAQ,iBAEjB,OAAtBmc,EAAAN,IAAAM,EAAwB7B,YAAYrS,QAAQ6J,IAC1CA,EAAM2B,gBAERiF,EAAA/Y,IAAA+Y,EAAY9V,cACNwZ,OAANA,EAAMT,QAAAS,EAAAA,EAAOxZ,eACPyZ,OAANA,EAAMT,QAAAS,EAAAA,EAAQzZ,SACd,IAAI0Z,IAAAA,QACY,OAAdA,EAAMR,QAAQ,EAARQ,EAAUC,WAChBT,EAAW,IACb,CAAE,MAAOG,GACT,CAAA,MAAMhb,CACR,CACF,CAKAxB,WAAAA,CACEC,EACAC,EACOgc,EACAC,EACAE,GAEPxQ,MAAM5L,EAASC,GAAYG,KAJpB6b,kBACAC,YAAA,EAAA9b,KACAgc,cARDU,EAAAA,KAAAA,+BACA7M,yBAAmB,EAAA7P,KA8CnB2c,sBAAyB3Z,IAMX,cAAhBhD,KAAKE,QACPF,KAAKH,WAAWiC,YAAY,CAC1B8a,iBAAkBzP,EAPEnK,EAAM4I,KAAK,GAOuByB,WAKpDwP,KAAAA,uBAAyB,EAAGjR,WAChB,YAAdA,EAAK/K,MACPb,KAAK2C,WAAWiJ,EAAKkR,SAAW,YAAc,aAEjD9c,KAEO+c,oBAAuBC,IAC7Bhd,KAAK8b,OAAOf,KAAKA,KAAKkC,sBACpBjd,KAAK8b,OAAO3W,QAAQ+X,aAEtBld,KAAK8b,OAAOf,KAAKA,KAAKoC,MAAQnd,KAAKG,OACnCH,KAAK8b,OAAOxN,QAAQiH,KAAKC,YAAY,CAAE3U,KAAM,qBAC7Cb,KAAK8b,OAAOxN,QAAQiH,KAAKC,YAAY,CACnC3U,KAAM,SACNwM,OAAQI,EAAoBuP,WAIxBI,aAAe,KAErBpd,KAAK2C,WAAW,aAChB3C,KAAK8b,OAAOxN,QAAQiH,KAAKC,YAAY,CAAE3U,KAAM,cAC7Cb,KAAK8b,OAAOf,KAAKA,KAAKsC,6BACpB,KACArd,KAAK8b,OAAO3W,QAAQ+X,YAAc,GAIpCxR,WAAW,KACT1L,KAAK8b,OAAOf,KAAKA,KAAKoC,MAAQnd,KAAKG,OACnCH,KAAK8b,OAAOxN,QAAQiH,KAAKC,YAAY,CAAE3U,KAAM,sBAC5C,MAGGyc,KAAAA,gBAAmBC,IACzB,GAA6B,IAAzBA,EAActV,OAChB,OACF,EAIA,IAAI9H,EAAS,EACb,IAAK,IAAI4N,EAAI,EAAGA,EAAIwP,EAActV,OAAQ8F,IACxC5N,GAAUod,EAAcxP,GAAK,IAI/B,OAFA5N,GAAUod,EAActV,OAEjB9H,EAAS,EAAI,EAAIA,EAAS,EAAI,EAAIA,GAC1CH,KA0IMyC,UAAY,EAAGtC,aAEpB,MAAMqd,EAAgBxU,OAAOyU,SAAStd,GAClCud,KAAKC,IAAI,EAAGD,KAAKE,IAAI,EAAGzd,IACxB,EACJH,KAAKG,OAASqd,EAEVxd,KAAKH,sBAAsBwP,EAE7BrP,KAAKH,WAAWmW,eAAewH,GAG/Bxd,KAAK8b,OAAOf,KAAKA,KAAKoC,MAAQK,GA5PzBxd,KAAK6b,MAALA,EACA7b,KAAM8b,OAANA,EACA9b,KAAQgc,SAARA,EAGPhc,KAAK6b,MAAMvN,QAAQiH,KAAKE,UAAYzV,KAAK2c,sBACzC3c,KAAK8b,OAAOxN,QAAQiH,KAAKE,UAAYzV,KAAK6c,sBAC5C,CAEmB,sBAAMlc,SACZ6K,MAAC7K,mBACZ,IAAI,IAAAkd,QACiB,OAAnBA,EAAM7d,KAAKgc,eAAQ,EAAb6B,EAAepB,WACrBzc,KAAKgc,SAAW,IAClB,CAAE,MAAOG,GAAI,OAEPnc,KAAK6b,MAAM/Y,cACP9C,KAAC8b,OAAOhZ,OACpB,CAEmBhC,kBAAAA,CAAmBkC,GACpCwI,MAAM1K,mBAAmBkC,GACzBhD,KAAKod,cACP,CAEmBxb,WAAAA,CAAYoB,GACkC,IAAA8a,EAAAC,EAA3D/d,KAAKD,wBAA0BiD,EAAM8S,YAAY/T,WACnD+b,OAAAA,GAAAC,EAAI/d,KAACJ,SAAQN,UAAbwe,EAAA5Z,KAAA6Z,EAAuB/a,EAAM8S,YAAYC,eAInC/V,KAAKH,sBAAsBwP,GAC/BrP,KAAK+c,oBAAoB/Z,EAAM8S,YAAYC,eAG7C/V,KAAKI,eAAiB4C,EAAM8S,YAAY/T,SACxC/B,KAAK+C,wBACL/C,KAAK2C,WAAW,YAEpB,CAiEO2D,WAAAA,CAAYC,GAEbvG,KAAKH,sBAAsBwP,EAC7BrP,KAAKH,WAAWyG,YAAYC,GAG5BvG,KAAK6b,MAAMnB,SAASnU,EAExB,CAEOC,yBAAAA,GAKL,aAJAxG,KAAK0c,qBAAL1c,KAAK0c,mBAAuB,IAAI/d,WAC9BqB,KAAK6b,MAAM9B,SAASzC,oBAEtBtX,KAAK6b,MAAM9B,SAASxC,qBAAqBvX,KAAK0c,oBACnC1c,KAAC0c,kBACd,CAEOjW,0BAAAA,GAEL,OAAIzG,KAAKH,sBAAsBwP,EACVrP,KAAKH,WAAW4G,8BAK5B,IAAI9H,WAAW,OAGA0Y,WAAnBxH,sBAAL7P,KAAK6P,oBAAwB,IAAIlR,WAC/BqB,KAAK8b,OAAO/B,SAASzC,oBAEvBtX,KAAK8b,OAAO/B,SAASxC,qBAAqBvX,KAAK6P,qBACxC7P,KAAK6P,oBACd,CAEOnJ,cAAAA,GACL,OAAW1G,KAACsd,gBAAgBtd,KAAKwG,4BACnC,CAEOG,eAAAA,GACL,OAAW3G,KAACsd,gBAAgBtd,KAAKyG,6BACnC,CAEO,uBAAMuX,EAAkBjV,WAC7BA,EAAUL,OACVA,EAAMqQ,8BACNA,EAA6BC,cAC7BA,IAEA,IAEE,GAAIhZ,KAAKH,sBAAsBuL,EAC7B,IAEE,kBADWyQ,MAAMlB,eAAe3B,QACpB6C,KACd,CAAE,MAAO1a,GACPgF,QAAQY,KACN,yDACA5F,EAGJ,CAIEnB,KAAKH,sBAAsBwP,cAClBxP,WAAW0W,oBAAoByC,GAAiB,UAIvDhZ,KAAK6b,MAAM/Y,QAEjB,MAAMmb,QAAiBnF,EAAMjN,OAAO,CAClC9C,WAAYA,MAAAA,EAAAA,EAAc/I,KAAKH,WAAWyL,YAAYvC,WACtDL,OAAc,MAANA,EAAAA,EAAU1I,KAAKH,WAAWyL,YAAY5C,OAC9CqQ,gCACAC,gBACAC,aAAcjZ,KAAKJ,QAAQqZ,aAC3BC,kBAAmBlZ,KAAKJ,QAAQsZ,oBAMlC,OAHAlZ,KAAK6b,MAAQoC,EACbje,KAAK6b,MAAMvN,QAAQiH,KAAKE,UAAYzV,KAAK2c,sBAElC3c,KAAK6b,KACd,CAAE,MAAO1a,GAEP,MADAgF,QAAQhF,MAAM,8BAA+BA,GACvCA,CACR,CACF,CAEO,wBAAM+c,EAAmBnV,WAC9BA,EAAUL,OACVA,EAAMiH,eACNA,IAEA,IAEE,GAAI3P,KAAKH,sBAAsBuL,EAC7B,IAEE,kBADW0Q,OAAOJ,gBAAgB/L,QACtBmM,MACd,CAAE,MAAO3a,GACPgF,QAAQY,KACN,0DACA5F,EAGJ,CAIEnB,KAAKH,sBAAsBwP,SACvBrP,KAAKH,WAAWoW,qBAAqBtG,GAAkB,UAIzD3P,KAAK8b,OAAOhZ,QAElB,MAAMqb,QAAkBrD,EAAOjP,OAAO,CACpC9C,WAAYA,MAAAA,EAAAA,EAAc/I,KAAKH,WAAW0L,aAAaxC,WACvDL,OAAc,MAANA,EAAAA,EAAU1I,KAAKH,WAAW0L,aAAa7C,OAC/CiH,iBACAsJ,aAAcjZ,KAAKJ,QAAQqZ,eAK7B,OAFAjZ,KAAK8b,OAASqC,OAEFrC,MACd,CAAE,MAAO3a,GAEP,MADAgF,QAAQhF,MAAM,+BAAgCA,GACxCA,CACR,CACF,ECjUI,SAAUid,EACd1b,EACA2b,EACArS,EAtBuB,6BAwBvB,MAAMiH,EAIF,GASJ,MAP8B,kBAAnBoL,EACTpL,EAAKqL,SAAWD,EAAiB,OAAS,WAE1CpL,EAAKsL,OAASF,EAAeE,OAC7BtL,EAAKuL,QAAUH,EAAeG,SAGzBvO,MAAM,GAAGjE,6BAAkCtJ,aAA2B,CAC3E+b,OAAQ,OACRxL,KAAM1O,KAAKC,UAAUyO,GACrByL,QAAS,CACP,eAAgB,qBAGtB,CCoBA,MAAMC,EAAYhf,WAAAA,GAAAK,KACR4e,UAA4D,IAAI1Q,GAAK,CAE7E+C,EAAAA,CAAGjO,EAAe6b,GACX7e,KAAK4e,UAAUE,IAAI9b,IACtBhD,KAAK4e,UAAUjQ,IAAI3L,EAAO,IAAI+b,KAEhC,MAAMC,EAAiBhf,KAAK4e,UAAUnQ,IAAIzL,GACtCgc,GACFA,EAAeC,IAAIJ,EAEvB,CAEA/N,GAAAA,CAAI9N,EAAe6b,GACjB,MAAMG,EAAiBhf,KAAK4e,UAAUnQ,IAAIzL,GACtCgc,GACFA,EAAeE,OAAOL,EAE1B,CAEAM,IAAAA,CAAKnc,KAAkBoc,GACrB,MAAMJ,EAAiBhf,KAAK4e,UAAUnQ,IAAIzL,GACtCgc,GACFA,EAAe7W,QAAQ0W,IACrBA,KAAYO,IAGlB,EAMU,IAAAC,GAAZ,SAAYA,GAEVA,EAAA,gBAAA,kBAEAA,EAAA,mBAAA,qBAEAA,EAAA,qBAAA,uBAEAA,EAAA,qCAAA,uCAEAA,EAAA,WAAA,aAEAA,EAAA,MAAA,QAEAA,EAAA,KAAA,OAEAA,EAAA,MAAA,QAEAA,EAAA,eAAA,iBAEAA,EAAA,iBAAA,mBAEAA,EAAA,kBAAA,oBAEAA,EAAA,iBAAA,mBAEAA,EAAA,aAAA,eAEAA,EAAA,YAAA,cAEAA,EAAA,eAAA,iBAEAA,EAAA,mBAAA,qBAEAA,EAAA,4BAAA,8BAEAA,EAAA,oBAAA,sBAEAA,EAAA,4BAAA,6BACD,CAvCD,CAAYA,IAAAA,EAuCX,CAAA,IA2DY,MAAAC,EAMX3f,WAAAA,CAAYoJ,GAAkB/I,KALtBuf,UAA8B,KAC9BC,KAAAA,aAA6B,IAAIb,EACjCc,KAAAA,kBAA4B,KAAKzf,KAClC0f,mBAAa,EAGlB1f,KAAKyf,kBAAoB1W,CAC3B,CAMO4W,YAAAA,CAAaJ,GAClBvf,KAAKuf,UAAYA,EAGbvf,KAAKuf,UAAUK,aAAerT,UAAUsT,KAC1C7f,KAAKwf,aAAaL,KAAKE,EAAeQ,MAGtC7f,KAAKuf,UAAU9T,iBAAiB,OAAQ,KACtCzL,KAAKwf,aAAaL,KAAKE,EAAeQ,QAI1C7f,KAAKuf,UAAU9T,iBAAiB,UAAYzI,IAC1C,IACE,MAAM4I,EAAOrH,KAAKoH,MAAM3I,EAAM4I,MAE9B,OAAQA,EAAKkU,cACX,IAAK,kBACH9f,KAAKwf,aAAaL,KAAKE,EAAeU,gBAAiBnU,GACvD,MACF,IAAK,qBACH5L,KAAKwf,aAAaL,KAAKE,EAAeW,mBAAoBpU,GAC1D,MACF,IAAK,uBACH5L,KAAKwf,aAAaL,KAAKE,EAAeY,qBAAsBrU,GAC5D,MACF,IAAK,uCACH5L,KAAKwf,aAAaL,KAChBE,EAAea,qCACftU,GAEF,MAEF,IAAK,aACH5L,KAAKwf,aAAaL,KAAKE,EAAec,WAAYvU,GAClD5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,iBACH5L,KAAKwf,aAAaL,KAAKE,EAAegB,eAAgBzU,GACtD5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,mBACH5L,KAAKwf,aAAaL,KAAKE,EAAeiB,iBAAkB1U,GACxD5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,oBACH5L,KAAKwf,aAAaL,KAAKE,EAAekB,kBAAmB3U,GACzD5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,mBACH5L,KAAKwf,aAAaL,KAAKE,EAAemB,iBAAkB5U,GACxD5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,eACH5L,KAAKwf,aAAaL,KAAKE,EAAeoB,aAAc7U,GACpD5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,cACH5L,KAAKwf,aAAaL,KAAKE,EAAeqB,YAAa9U,GACnD5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,iBACH5L,KAAKwf,aAAaL,KAAKE,EAAesB,eAAgB/U,GACtD5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,qBACH5L,KAAKwf,aAAaL,KAAKE,EAAeuB,mBAAoBhV,GAC1D5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,8BACH5L,KAAKwf,aAAaL,KAChBE,EAAewB,4BACfjV,GAEF5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,sBACH5L,KAAKwf,aAAaL,KAAKE,EAAeyB,oBAAqBlV,GAC3D5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,8BACH5L,KAAKwf,aAAaL,KAChBE,EAAe0B,4BACfnV,GAEF5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,IAAK,QACH5L,KAAKwf,aAAaL,KAAKE,EAAee,MAAOxU,GAC7C,MACF,QACEzF,QAAQY,KAAK,wBAAyB6E,GAE5C,CAAE,MAAOzK,GACPgF,QAAQhF,MAAM,qCAAsCA,EAAO6B,EAAM4I,MACjE5L,KAAKwf,aAAaL,KAChBE,EAAee,MACf,IAAIhf,MAAM,4BAA4BD,KAE1C,IAGFnB,KAAKuf,UAAU9T,iBAAiB,QAAUtK,IACxCgF,QAAQhF,MAAM,mBAAoBA,GAClCnB,KAAKwf,aAAaL,KAAKE,EAAee,MAAOjf,KAG/CnB,KAAKuf,UAAU9T,iBAAiB,QAAUzI,IAMxC,GALAmD,QAAQ6a,IACN,0BAA0Bhe,EAAM+C,iBAAiB/C,EAAMH,qBAAqBG,EAAMie,aAI/Eje,EAAMie,UAA4B,MAAfje,EAAM+C,MAAgC,OAAf/C,EAAM+C,KAAgB,CACnE,MAAMmb,EAAe,kCAAkCle,EAAM+C,UAAU/C,EAAMH,QAAU,uBACvFsD,QAAQhF,MAAM+f,GACdlhB,KAAKwf,aAAaL,KAAKE,EAAee,MAAO,IAAIhf,MAAM8f,GACzD,CAEAlhB,KAAKwf,aAAaL,KAAKE,EAAe8B,MAAOne,IAEjD,CAuBOiO,EAAAA,CACLjO,EACA6b,GAIA7e,KAAKwf,aAAavO,GAAGjO,EAAO6b,EAC9B,CAiBO/N,GAAAA,CACL9N,EACA6b,GAIA7e,KAAKwf,aAAa1O,IAAI9N,EAAO6b,EAC/B,CA4BOhS,IAAAA,CAAKjB,GAKX,IAAAwV,EAAAC,EACC,IAAKrhB,KAAKuf,WAAavf,KAAKuf,UAAUK,aAAerT,UAAUsT,KAC7D,MAAM,IAAIze,MAAM,8BAGlB,MAAMC,EAA2B,CAC/Bye,aAAc,oBACd/J,cAAenK,EAAK0V,YACpBC,cAAMH,EAAExV,EAAK2V,SAAMH,EACnBI,YAA4B,OAAjBH,EAAEzV,EAAK7C,YAAUsY,EAAIrhB,KAAKyf,kBACrCgC,cAAe7V,EAAK8V,cAGtB1hB,KAAKuf,UAAU1S,KAAKtI,KAAKC,UAAUnD,GACrC,CAuBOkgB,MAAAA,GACL,IAAKvhB,KAAKuf,WAAavf,KAAKuf,UAAUK,aAAerT,UAAUsT,KAC7D,MAAM,IAAIze,MAAM,8BAUlBpB,KAAKuf,UAAU1S,KAAKtI,KAAKC,UAPQ,CAC/Bsb,aAAc,oBACd/J,cAAe,GACfwL,QAAQ,EACRC,YAAaxhB,KAAKyf,oBAItB,CAkBO3c,KAAAA,GAED9C,KAAK0f,eACP1f,KAAK0f,gBAIH1f,KAAKuf,WACPvf,KAAKuf,UAAUzc,OAEnB,EC7eK,MAAM6e,EAA2BxT,EACtC,uBAEA,ogDCHU,IAAAyT,EAUAC,GAVZ,SAAYD,GACVA,EAAA,SAAA,WACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,YACAA,EAAA,UAAA,WACD,CARD,CAAYA,IAAAA,EAQX,CAAA,IAED,SAAYC,GACVA,EAAA,OAAA,SACAA,EAAA,IAAA,KACD,CAHD,CAAYA,IAAAA,EAGX,CAAA,UAiFYC,EAGH,sBAAOC,CACbC,EAAkBF,EAAeG,kBAEjC,MAAO,GAAGD,8BACZ,CAEQ,wBAAOE,CACbtiB,GAEA,MAAMoiB,EAAUF,EAAeC,gBAAgBniB,EAAQoiB,SACjDG,EAAS,IAAIC,gBAWnB,GARAD,EAAOE,OAAO,WAAYziB,EAAQ0iB,SAElCH,EAAOE,OAAO,QAASziB,EAAQyQ,YAGAkS,IAA3B3iB,EAAQ4iB,gBACVL,EAAOE,OAAO,kBAAmBziB,EAAQ4iB,qBAEHD,IAApC3iB,EAAQ6iB,wBAAuC,CACjD,GACE7iB,EAAQ6iB,yBAA2B,IACnC7iB,EAAQ6iB,wBAA0B,EAElC,MAAM,IAAIrhB,MAAM,uDAElB+gB,EAAOE,OACL,6BACAziB,EAAQ6iB,wBAAwBnR,WAEpC,CACA,QAA6BiR,IAAzB3iB,EAAQ8iB,aAA4B,CACtC,GAAI9iB,EAAQ8iB,aAAe,IAAO9iB,EAAQ8iB,aAAe,GACvD,MAAM,IAAIthB,MAAM,4CAElB+gB,EAAOE,OAAO,gBAAiBziB,EAAQ8iB,aAAapR,WACtD,CACA,QAAoCiR,IAAhC3iB,EAAQ+iB,oBAAmC,CAC7C,GACE/iB,EAAQ+iB,qBAAuB,IAC/B/iB,EAAQ+iB,oBAAsB,IAE9B,MAAU,IAAAvhB,MAAM,mDAElB+gB,EAAOE,OACL,yBACAziB,EAAQ+iB,oBAAoBrR,WAEhC,CACA,QAAqCiR,IAAjC3iB,EAAQgjB,qBAAoC,CAC9C,GACEhjB,EAAQgjB,sBAAwB,IAChChjB,EAAQgjB,qBAAuB,IAE/B,UAAUxhB,MAAM,oDAElB+gB,EAAOE,OACL,0BACAziB,EAAQgjB,qBAAqBtR,WAEjC,MAC6BiR,IAAzB3iB,EAAQijB,cACVV,EAAOE,OAAO,gBAAiBziB,EAAQijB,mBAEPN,IAA9B3iB,EAAQkjB,mBACVX,EAAOE,OACL,qBACAziB,EAAQkjB,kBAAoB,OAAS,SAIzC,MAAMC,EAAcZ,EAAO7Q,WAC3B,OAAOyR,EAAc,GAAGf,KAAWe,IAAgBf,CACrD,CA6BO,cAAOpR,CACZhR,GAEA,IAAKA,EAAQ0iB,QACX,MAAM,IAAIlhB,MAAM,uBAIlB,MAIMvB,EAAa,IAAIyf,EAHrB,eAAgB1f,GAAWA,EAAQojB,WAC/B,KACCpjB,EAAyBmJ,YAI1Bka,EAAMnB,EAAeI,kBAAkBtiB,GAEvC2f,EAAY,IAAIhT,UAAU0W,GAchC,MAXI,eAAgBrjB,GAAWA,EAAQojB,YACrCzD,EAAU9T,iBAAiB,OAAQ,KACjCqW,EAAeoB,qBACbtjB,EACAC,KAKNA,EAAW8f,aAAaJ,GAEjB1f,CACT,CAEQ,iCAAaqjB,CACnBtjB,EACAC,GAEA,IAAI,IAAAsjB,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAEF,MAAMrI,QAAe1D,UAAUyB,aAAac,aAAa,CACvDC,MAAO,CACLlE,SAA4B,OAApBiN,EAAEvjB,EAAQojB,iBAAU,EAAlBG,EAAoBjN,SAC9BU,iBAAsD,OAAtCwM,EAAoB,OAApBC,EAAEzjB,EAAQojB,iBAAU,EAAlBK,EAAoBzM,mBAAgBwM,EACtDvM,iBAAsD,OAAtCyM,EAAoB,OAApBC,EAAE3jB,EAAQojB,iBAAU,EAAlBO,EAAoB1M,mBAAgByM,EACtDxM,gBAAoD,OAArC0M,EAAEC,OAAFA,EAAE7jB,EAAQojB,iBAARS,EAAAA,EAAoB3M,kBAAe0M,EACpDzM,aAA8C,OAAlC2M,EAAoB,OAApBC,EAAE/jB,EAAQojB,iBAAU,EAAlBW,EAAoB5M,cAAY2M,EAAI,EAClD3a,WAAY,CAAEiO,MAAO,SAKnBpC,EAAe,IAAIC,aAAa,CAAE9L,WAAY,aAG9C4Y,EAAyB/M,EAAaS,cAG5C,MAAMnS,EAAS0R,EAAaQ,wBAAwBkG,GAC9CsI,EAAc,IAAItO,iBACtBV,EACA,wBAIFgP,EAAYrO,KAAKE,UAAYzS,IAC3B,MAAM0S,UAAEA,GAAc1S,EAAM4I,KAEtBkC,EAAQ,IAAInP,WAAW+W,GAC7B,IAAImO,EAAS,GACb,IAAK,IAAI9V,EAAI,EAAGA,EAAID,EAAM7F,OAAQ8F,IAChC8V,GAAUviB,OAAOkM,aAAaM,EAAMC,IAEtC,MAAM6H,EAAcrI,KAAKsW,GAEzBhkB,EAAWgN,KAAK,CAAEyU,YAAa1L,KAIjC1S,EAAO0N,QAAQgT,GAGY,cAAvBhP,EAAapD,aACToD,EAAayF,SAIrBxa,EAAW6f,cAAgB,KACzBpE,EAAOd,YAAYrS,QAAQ6J,IACzBA,EAAM2B,SAERzQ,EAAOmF,aACPub,EAAYvb,aACZuM,EAAa9R,QAEjB,CAAE,MAAO3B,GAEP,MADAgF,QAAQhF,MAAM,wCAAyCA,GACjDA,CACR,CACF,EA9MW2gB,EACaG,iBAAmB,0BClCvC,MAAO6B,UAAqBllB,EACzB,mBAAO6Z,CAAa7Y,GACzB,OAAOA,EAAQ8K,SACX8N,EAAiBC,aAAa7Y,GAC9B+b,EAAkBlD,aAAa7Y,EACrC"}